{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_precision_score(y_true, y_score, k=10):\n",
    "    \"\"\"Precision at rank k\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like, shape = [n_samples]\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array-like, shape = [n_samples]\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "        Rank.\n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "    \"\"\"\n",
    "    unique_y = np.unique(y_true)\n",
    "\n",
    "    if len(unique_y) == 2:\n",
    "        pos_label = unique_y[1]\n",
    "        n_pos = np.sum(y_true == pos_label)\n",
    "\n",
    "        order = np.argsort(y_score)[::-1]\n",
    "        y_true = np.take(y_true, order[:k])\n",
    "        n_relevant = np.sum(y_true == pos_label)\n",
    "\n",
    "        # Divide by min(n_pos, k) such that the best achievable score is always 1.0.\n",
    "        return float(n_relevant) / min(n_pos, k)\n",
    "    else:\n",
    "        return -1\n",
    "def rank_precision(data_frame,k=4): # passed to groupby object \n",
    "    y_true=list(data_frame[1])\n",
    "    y_score=list(data_frame[2])\n",
    "    return ranking_precision_score(y_true, y_score, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,name=\"GBDT\",alpha=0,penalty=0,topk=-1,attrN=-1,preds=None,rmse=-1):\n",
    "        self.name=name  # name can be GBDT or GBDTBT (GBDT with top ranking feature from BT)\n",
    "        self.pen=penalty\n",
    "        self.topk=topk\n",
    "        self.preds=preds\n",
    "        self.attrN=attrN\n",
    "        self.alpha=alpha\n",
    "        self.rmse=rmse\n",
    "        \n",
    "    def get_AUC(self):\n",
    "        return roc_auc_score(trueY,self.preds) if self.preds is not None else None\n",
    "    \n",
    "    #add some other metrics later\n",
    "    \n",
    "    def get_ranking_precision(self,k=2): # ranking_precision_score averaged over queries\n",
    "        combined=pd.concat([kw,trueY,self.preds],axis=1,ignore_index=True)\n",
    "        grouped=combined.groupby(combined[0])\n",
    "        agged=grouped.apply(rank_precision,k=k)\n",
    "        agged=[num for num in agged if num>=0]\n",
    "        return sum(agged)/(len(agged)) if len(agged)>0 else 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### result files paths\n",
    "\n",
    "# result_path='result/us/'\n",
    "# attr_total=174\n",
    "\n",
    "# result_path='result/us_adaptive'\n",
    "# attr_total=174\n",
    "\n",
    "# result_path='result/gold_in_qa_split_new/'\n",
    "# attr_total=96\n",
    "\n",
    "result_path='result/gold_in_qa_split_adaptive/'\n",
    "attr_total=96\n",
    "\n",
    "\n",
    "# result_path='result/madelon/'\n",
    "# attr_total=500\n",
    "\n",
    "# result_path='result/madelon_adaptive/'\n",
    "# attr_total=500\n",
    "\n",
    "\n",
    "\n",
    "# result_path='synthetic/result_syn1_test/'\n",
    "# aux_path='synthetic/aux_result_syn1_test/'\n",
    "# attr_total=100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess\n",
    "\n",
    "filenames_result=listdir(result_path)\n",
    "trueY=pd.read_csv(result_path+\"trueY.txt\",header=None)[0]\n",
    "try:\n",
    "    kw=pd.read_csv(result_path+\"keyword.txt\",header=None)[0]\n",
    "except:\n",
    "    print(\"do not have groups\")\n",
    "try:\n",
    "    number_unused=len(pd.read_csv(result_path+\"preprocess_unused.txt\",header=None))\n",
    "except:\n",
    "    number_unused=0\n",
    "attr_init_number=attr_total-number_unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_init_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boosting_rms_GBFS_mu0.9_alpha0.txt',\n",
       " 'log_GBFS_mu0.08_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.8_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.55_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.01_alpha0.txt',\n",
       " 'log_GBFS_mu0.01_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.02_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.5_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.25_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.6_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.8_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.3_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.05_alpha0.txt',\n",
       " 'log_GBFS_mu0.01_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.5_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.6_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.25_alpha0.1.txt',\n",
       " 'GBFS_mu0.12_preds_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.5_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.2_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.7_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.4_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.01_alpha0.02.txt',\n",
       " 'GBFS_mu0.35_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.45_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.4_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.02_alpha0.txt',\n",
       " 'GBFS_mu0.08_preds_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.08_alpha0.txt',\n",
       " 'log_GBFS_mu0.08_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.9_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.01_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.8_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.01_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.1_alpha0.txt',\n",
       " 'log_GBFS_mu0.12_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.18_alpha0.01.txt',\n",
       " 'GBFS_mu0.7_preds_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.35_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.1_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.95_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.18_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.9_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.55_alpha0.txt',\n",
       " 'log_GBFS_mu0.3_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.1_alpha0.1.txt',\n",
       " 'GBFS_mu0.08_preds_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.1_alpha0.02.txt',\n",
       " 'GBFS_mu0.6_preds_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.5_alpha0.1.txt',\n",
       " 'GBFS_mu0.2_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.9_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.18_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.2_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.18_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.55_alpha0.001.txt',\n",
       " 'GBFS_mu0.15_preds_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.35_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.35_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.95_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.9_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.5_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.55_alpha0.001.txt',\n",
       " 'GBFS_mu0.02_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.35_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.12_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.05_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.18_alpha0.001.txt',\n",
       " 'GBFS_mu0.45_preds_alpha0.02.txt',\n",
       " 'GBFS_mu0.55_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.18_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.3_alpha0.txt',\n",
       " 'log_GBFS_mu0.02_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.2_alpha0.02.txt',\n",
       " 'GBFS_mu0.9_preds_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.8_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.15_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.35_alpha0.1.txt',\n",
       " 'GBFS_mu0.4_preds_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.55_alpha0.01.txt',\n",
       " 'GBFS_mu0.45_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.08_alpha0.txt',\n",
       " 'log_GBFS_mu0.9_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.2_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.01_alpha0.1.txt',\n",
       " 'GBFS_mu0.8_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.5_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.25_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.05_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.18_alpha0.txt',\n",
       " 'GBFS_mu0.4_preds_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.15_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.18_alpha0.001.txt',\n",
       " 'GBFS_mu0.95_preds_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.2_alpha0.001.txt',\n",
       " 'GBFS_mu0.01_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.25_preds_alpha0.01.txt',\n",
       " 'GBFS_mu0.12_preds_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.1_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.02_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.25_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.02_alpha0.01.txt',\n",
       " 'trueY.txt',\n",
       " 'GBFS_mu0.8_preds_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.5_alpha0.001.txt',\n",
       " 'GBFS_mu0.18_preds_alpha0.02.txt',\n",
       " 'preprocess_unused.txt',\n",
       " 'feature_scores_GBFS_mu0.55_alpha0.01.txt',\n",
       " 'GBFS_mu0.02_preds_alpha0.02.txt',\n",
       " 'GBFS_mu0.18_preds_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.8_alpha0.1.txt',\n",
       " 'GBFS_mu0.35_preds_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.3_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.2_alpha0.txt',\n",
       " 'GBFS_mu0.2_preds_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.05_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.8_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.05_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.9_alpha0.001.txt',\n",
       " 'GBFS_mu0.5_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.18_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.01_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.02_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.1_alpha0.02.txt',\n",
       " 'GBFS_mu0.18_preds_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.12_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.6_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.4_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.3_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.4_alpha0.02.txt',\n",
       " 'GBFS_mu0.25_preds_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.25_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.3_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.15_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.1_alpha0.txt',\n",
       " 'GBFS_mu0.6_preds_alpha0.02.txt',\n",
       " 'GBFS_mu0.12_preds_alpha0.1.txt',\n",
       " 'GBFS_mu0.55_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.18_alpha0.1.txt',\n",
       " 'GBFS_mu0.05_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.05_alpha0.02.txt',\n",
       " 'GBFS_mu0.18_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.7_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.08_alpha0.02.txt',\n",
       " 'GBFS_mu0.18_preds_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.95_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.2_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.18_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.12_alpha0.txt',\n",
       " 'GBFS_mu0.7_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.55_alpha0.001.txt',\n",
       " 'GBFS_mu0.35_preds_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.6_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.12_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.6_alpha0.txt',\n",
       " 'GBFS_mu0.12_preds_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.35_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.2_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.18_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.05_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.12_alpha0.001.txt',\n",
       " 'GBFS_mu0.15_preds_alpha0.txt',\n",
       " 'log_GBFS_mu0.25_alpha0.txt',\n",
       " 'log_GBFS_mu0.7_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.45_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.4_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.55_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.15_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.12_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.8_alpha0.01.txt',\n",
       " 'GBFS_mu0.25_preds_alpha0.txt',\n",
       " 'GBFS_mu0.6_preds_alpha0.01.txt',\n",
       " 'GBFS_mu0.35_preds_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.2_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.15_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.8_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.45_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.12_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.3_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.45_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.01_alpha0.txt',\n",
       " 'GBFS_mu0.6_preds_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.45_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.6_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.02_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.55_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.4_alpha0.02.txt',\n",
       " 'GBFS_mu0.5_preds_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.01_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.15_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.4_alpha0.01.txt',\n",
       " 'GBFS_mu0.8_preds_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.55_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.7_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.8_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.5_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.05_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.01_alpha0.001.txt',\n",
       " 'GBFS_mu0.02_preds_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.25_alpha0.02.txt',\n",
       " 'GBFS_mu0.55_preds_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.8_alpha0.02.txt',\n",
       " 'GBFS_mu0.1_preds_alpha0.02.txt',\n",
       " 'GBFS_mu0.4_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.12_alpha0.02.txt',\n",
       " 'GBFS_mu0.5_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.25_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.1_alpha0.1.txt',\n",
       " 'GBFS_mu0.01_preds_alpha0.02.txt',\n",
       " 'GBFS_mu0.1_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.95_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.12_alpha0.txt',\n",
       " 'log_GBFS_mu0.9_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.5_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.05_alpha0.txt',\n",
       " 'GBFS_mu0.95_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.95_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.3_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.01_alpha0.01.txt',\n",
       " 'GBFS_mu0.8_preds_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.6_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.18_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.02_alpha0.01.txt',\n",
       " 'GBFS_mu0.05_preds_alpha0.txt',\n",
       " 'log_GBFS_mu0.6_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.08_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.08_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.95_alpha0.1.txt',\n",
       " 'GBFS_mu0.3_preds_alpha0.txt',\n",
       " 'GBFS_mu0.3_preds_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.3_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.02_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.35_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.9_alpha0.1.txt',\n",
       " 'GBFS_mu0.4_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.95_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.55_alpha0.02.txt',\n",
       " 'GBFS_mu0.45_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.8_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.5_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.02_alpha0.01.txt',\n",
       " 'GBFS_mu0.01_preds_alpha0.txt',\n",
       " 'gold_in_qa_split_test.dta',\n",
       " 'feature_scores_GBFS_mu0.4_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.7_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.2_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.7_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.1_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.95_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.45_alpha0.02.txt',\n",
       " 'gold_in_qa_split_train.attr',\n",
       " 'GBFS_mu0.15_preds_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.4_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.05_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.15_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.02_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.05_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.45_alpha0.txt',\n",
       " 'GBFS_mu0.9_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.08_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.15_preds_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.7_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.3_alpha0.01.txt',\n",
       " 'GBFS_mu0.2_preds_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.45_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.01_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.6_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.7_alpha0.txt',\n",
       " 'GBFS_mu0.3_preds_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.55_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.15_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.2_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.95_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.25_alpha0.001.txt',\n",
       " 'GBFS_mu0.7_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.55_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.95_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.35_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.8_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.45_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.9_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.5_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.6_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.3_alpha0.001.txt',\n",
       " 'GBFS_mu0.9_preds_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.2_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.1_alpha0.01.txt',\n",
       " 'GBFS_mu0.05_preds_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.3_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.02_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.45_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.35_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.08_alpha0.1.txt',\n",
       " 'GBFS_mu0.1_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.7_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.9_alpha0.02.txt',\n",
       " 'GBFS_mu0.05_preds_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.02_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.6_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.6_alpha0.01.txt',\n",
       " 'GBFS_mu0.5_preds_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.7_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.12_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.2_alpha0.01.txt',\n",
       " 'GBFS_mu0.12_preds_alpha0.txt',\n",
       " 'log_GBFS_mu0.45_alpha0.txt',\n",
       " 'log_GBFS_mu0.8_alpha0.001.txt',\n",
       " 'keyword.txt',\n",
       " 'boosting_rms_GBFS_mu0.55_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.08_alpha0.01.txt',\n",
       " 'GBFS_mu0.55_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.01_preds_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.1_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.08_alpha0.001.txt',\n",
       " 'GBFS_mu0.95_preds_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.1_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.35_alpha0.txt',\n",
       " 'GBFS_mu0.25_preds_alpha0.1.txt',\n",
       " 'GBFS_mu0.9_preds_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.5_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.35_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.45_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.7_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.08_alpha0.001.txt',\n",
       " 'GBFS_mu0.02_preds_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.25_alpha0.txt',\n",
       " 'log_GBFS_mu0.15_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.25_alpha0.02.txt',\n",
       " 'GBFS_mu0.25_preds_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.9_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.1_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.2_alpha0.txt',\n",
       " 'log_GBFS_mu0.4_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.12_alpha0.001.txt',\n",
       " 'GBFS_mu0.45_preds_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.7_alpha0.001.txt',\n",
       " 'GBFS_mu0.08_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.02_alpha0.txt',\n",
       " 'GBFS_mu0.15_preds_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.2_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.01_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.1_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.35_alpha0.1.txt',\n",
       " 'GBFS_mu0.01_preds_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.9_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.1_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.6_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.7_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.4_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.05_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.7_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.95_alpha0.01.txt',\n",
       " 'GBFS_mu0.35_preds_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.25_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.6_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.15_alpha0.01.txt',\n",
       " 'GBFS_mu0.6_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.55_preds_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.35_alpha0.01.txt',\n",
       " 'GBFS_mu0.3_preds_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.08_alpha0.02.txt',\n",
       " 'GBFS_mu0.8_preds_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.35_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.05_alpha0.001.txt',\n",
       " 'GBFS_mu0.1_preds_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.45_alpha0.02.txt',\n",
       " 'GBFS_mu0.2_preds_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.08_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.35_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.4_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.45_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.9_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.05_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.5_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.3_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.12_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.25_alpha0.01.txt',\n",
       " 'GBFS_mu0.02_preds_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.4_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.08_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.45_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.05_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.8_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.3_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.95_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.5_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.15_alpha0.1.txt',\n",
       " 'GBFS_mu0.95_preds_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.15_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.4_alpha0.txt',\n",
       " 'GBFS_mu0.7_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.2_preds_alpha0.1.txt',\n",
       " 'GBFS_mu0.05_preds_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.25_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.15_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.02_alpha0.txt',\n",
       " 'GBFS_mu0.9_preds_alpha0.txt',\n",
       " 'log_GBFS_mu0.15_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.7_alpha0.01.txt',\n",
       " 'GBFS_mu0.45_preds_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.95_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.8_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.15_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.01_alpha0.txt',\n",
       " 'GBFS_mu0.3_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.55_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.5_alpha0.txt',\n",
       " 'GBFS_mu0.1_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.12_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.6_alpha0.01.txt',\n",
       " 'GBFS_mu0.08_preds_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.18_alpha0.txt',\n",
       " 'GBFS_mu0.5_preds_alpha0.txt',\n",
       " 'log_GBFS_mu0.9_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.08_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.4_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.3_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.18_alpha0.txt',\n",
       " 'gold_in_qa_split_train.dta',\n",
       " 'log_GBFS_mu0.25_alpha0.01.txt',\n",
       " 'GBFS_mu0.4_preds_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.95_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.12_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.95_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.95_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.7_alpha0.1.txt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store result for adaptive GBFS\n",
    "GBFS_adaptive_dict=collections.defaultdict(dict) # store preds,attrN for different 0<mu<1 and alpha\n",
    "for filename in filenames_result:\n",
    "    last_dot=filename.rfind(\".\")\n",
    "    fname,fext=filename[:last_dot],filename[last_dot+1:]\n",
    "    if fext==\"txt\" and \"_alpha\" in fname:\n",
    "        alpha=float(fname[fname.index(\"_alpha\")+6:])\n",
    "        if \"_preds\" in fname:\n",
    "            preds=pd.read_csv(result_path+filename,header=None)[0]\n",
    "            idx=fname.index(\"_mu\")\n",
    "            mu=float(fname[idx+3:fname.index(\"_preds\")])\n",
    "            GBFS_adaptive_dict[mu,alpha][\"preds\"]=preds\n",
    "        elif \"feature_scores_\" in fname:\n",
    "            tmp=pd.read_csv(result_path+filename,header=None)[0][0] # the first line of feature_score reports attrN\n",
    "            attrN=int(tmp.split()[-1])\n",
    "            idx=fname.index(\"_mu\")\n",
    "            mu=float(fname[idx+3:fname.index(\"_alpha\")])\n",
    "            GBFS_adaptive_dict[mu,alpha][\"attrN\"]=attrN\n",
    "        elif \"boosting_rms_\" in fname:\n",
    "            rmse=pd.read_csv(result_path+filename,header=None)[0].iloc[-1] # last line is the rmse\n",
    "            idx=fname.index(\"_mu\")\n",
    "            mu=float(fname[idx+3:fname.index(\"_alpha\")])\n",
    "            GBFS_adaptive_dict[mu,alpha][\"rmse\"]=rmse\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version problem\n",
      "version problem\n",
      "version problem\n",
      "version problem\n",
      "version problem\n"
     ]
    }
   ],
   "source": [
    "# store results when go through all files in result folder\n",
    "# index result like [(mu,alpha)]\n",
    "GBFS_dict=collections.defaultdict(dict) # store preds,attrN,rmse for different mu>0 and alpha\n",
    "GBDTt_dict=collections.defaultdict(dict) # indexed by alpha,topk\n",
    "GBDTBTt_dict=collections.defaultdict(dict) # store attrN and preds,rmse\n",
    "AttrN_GBDT={} # initial number of attr used for indexed by alpha\n",
    "AttrN_BT={} \n",
    "for filename in filenames_result:\n",
    "    last_dot=filename.rfind(\".\")\n",
    "    fname,fext=filename[:last_dot],filename[last_dot+1:]\n",
    "    if fext==\"txt\" and \"_alpha\" in fname:\n",
    "        alpha=float(fname[fname.index(\"_alpha\")+6:])\n",
    "        if \"_preds\" in fname:\n",
    "            preds=pd.read_csv(result_path+filename,header=None)[0]\n",
    "            if \"GBFSt\" in fname:\n",
    "                topk=int(fname[5:fname.index(\"_mu\")])\n",
    "                GBDTt_dict[alpha,topk][\"preds\"]=preds\n",
    "            elif \"GBDTBTt\" in fname:\n",
    "                topk=int(fname[7:fname.index(\"_preds\")])\n",
    "                GBDTBTt_dict[alpha,topk][\"preds\"]=preds\n",
    "            else:\n",
    "                idx=fname.index(\"_mu\")\n",
    "                mu=float(fname[idx+3:fname.index(\"_preds\")])\n",
    "                GBFS_dict[mu,alpha][\"preds\"]=preds\n",
    "        elif \"feature_scores_\" in fname:\n",
    "            tmp=pd.read_csv(result_path+filename,header=None)[0][0] # the first line of feature_score reports attrN\n",
    "            try:\n",
    "                attrN=int(tmp.split()[-1])\n",
    "            except:\n",
    "                print(\"version problem\")\n",
    "                attrN=attr_init_number\n",
    "            if \"_mu\" in fname:\n",
    "                idx=fname.index(\"_mu\")\n",
    "                mu=float(fname[idx+3:fname.index(\"_alpha\")])\n",
    "                GBFS_dict[mu,alpha][\"attrN\"]=attrN\n",
    "            elif \"_GBDT\" in fname:\n",
    "                AttrN_GBDT[alpha]=attrN\n",
    "                GBFS_dict[0,alpha][\"attrN\"]=attrN\n",
    "            else:\n",
    "                AttrN_BT[alpha]=attrN\n",
    "                \n",
    "        elif \"boosting_rms_\" in fname:\n",
    "            rmse=pd.read_csv(result_path+filename,header=None)[0].iloc[-1] # last line is the rmse\n",
    "            if \"GBFSt\" in fname:\n",
    "                topk=int(fname[18:fname.index(\"_mu\")])\n",
    "                GBDTt_dict[alpha,topk][\"rmse\"]=rmse\n",
    "            elif \"GBDTBTt\" in fname:\n",
    "                topk=int(fname[20:fname.index(\"_alpha\")])\n",
    "                GBDTBTt_dict[alpha,topk][\"rmse\"]=rmse\n",
    "            else:\n",
    "                idx=fname.index(\"_mu\")\n",
    "                mu=float(fname[idx+3:fname.index(\"_alpha\")])\n",
    "                GBFS_dict[mu,alpha][\"rmse\"]=rmse\n",
    "# get attrN's for GBDTt amd GBDTBTt which is min(topk,initial attrN in AttrN_GBDT and AttrN_BT for different alpha)\n",
    "for alpha,topk in GBDTt_dict:\n",
    "    GBDTt_dict[alpha,topk][\"attrN\"]=min(topk,AttrN_GBDT[alpha])\n",
    "for alpha,topk in GBDTBTt_dict:\n",
    "    GBDTBTt_dict[alpha,topk][\"attrN\"]=min(topk,AttrN_BT[alpha])\n",
    "\n",
    "                    \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put result together\n",
    "model_results=collections.defaultdict(list) # indexed by mu,alpha\n",
    "# GBFS model\n",
    "for mu,alpha in GBFS_dict:\n",
    "    try:\n",
    "        attrN=GBFS_dict[mu,alpha][\"attrN\"]\n",
    "        preds=GBFS_dict[mu,alpha][\"preds\"]\n",
    "        rmse=GBFS_dict[mu,alpha][\"rmse\"]\n",
    "        model_results[mu,alpha].append(Model(penalty=mu,alpha=alpha,topk=-1,attrN=attrN,preds=preds,rmse=rmse))\n",
    "    except:\n",
    "        print(\"not ready\")\n",
    "# GBDTt model\n",
    "for alpha,topk in GBDTt_dict:\n",
    "    preds=GBDTt_dict[alpha,topk][\"preds\"]\n",
    "    attrN=GBDTt_dict[alpha,topk][\"attrN\"]\n",
    "    rmse=GBDTt_dict[alpha,topk][\"rmse\"]\n",
    "    model_results[0,alpha].append(Model(alpha=alpha,topk=topk,attrN=attrN,preds=preds,rmse=rmse))\n",
    "    \n",
    "\n",
    "# GBDTBTt model\n",
    "for alpha,topk in GBDTBTt_dict:\n",
    "    preds=GBDTBTt_dict[alpha,topk][\"preds\"]\n",
    "    attrN=GBDTBTt_dict[alpha,topk][\"attrN\"]\n",
    "    rmse=GBDTBTt_dict[alpha,topk][\"rmse\"]\n",
    "    model_results[0,alpha].append(Model(name=\"GBDTBT\",alpha=alpha,topk=topk,attrN=attrN,preds=preds,rmse=rmse))\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBFS_adaptive model (0=<mu<=1)\n",
    "for mu,alpha in GBFS_adaptive_dict:\n",
    "    attrN=GBFS_adaptive_dict[mu,alpha][\"attrN\"]\n",
    "    preds=GBFS_adaptive_dict[mu,alpha][\"preds\"]\n",
    "    rmse=GBFS_adaptive_dict[mu,alpha][\"rmse\"]\n",
    "    model_results[mu,alpha].append(Model(penalty=mu,alpha=alpha,topk=-1,attrN=attrN,preds=preds,rmse=rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plots\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus=sorted(set(idx[0] for idx in GBFS_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=sorted(set(idx[1] for idx in GBFS_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot1 attrN v.s. mus for GBFS\n",
    "for alpha in alphas:\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x_axis=mus\n",
    "    y_axis=[GBFS_dict[mu,alpha][\"attrN\"] for mu in x_axis]\n",
    "    plt.plot(x_axis, y_axis, color='b',marker=\"o\",\n",
    "             lw=lw, label='GBFS')\n",
    "    #plt.xlim([0.0, max(x_axis)])\n",
    "    #plt.ylim([20, 100])\n",
    "    plt.xlabel('Penalty parameter mu')\n",
    "    plt.ylabel('Number of active features')\n",
    "    plt.title(f'Number of active features v.s. Penalty parameter mu with alpha={alpha}')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphas=[0,0.001,0.01,0.02,0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot1 attrN v.s. mus for GBFS_adaptive\n",
    "# for alpha in alphas:\n",
    "#     plt.figure()\n",
    "#     lw = 2\n",
    "#     x_axis=sorted(set(idx[0] for idx in GBFS_adaptive_dict.keys()))\n",
    "#     y_axis=[GBFS_adaptive_dict[mu,alpha][\"attrN\"] for mu in x_axis]\n",
    "#     plt.plot(x_axis, y_axis, color='b',marker=\"o\",\n",
    "#              lw=lw, label='GBFS')\n",
    "#     #plt.xlim([0.0, max(x_axis)])\n",
    "#     #plt.ylim([20, 100])\n",
    "#     plt.xlabel('Adaptive penalty parameter mu')\n",
    "#     plt.ylabel('Number of active features')\n",
    "#     plt.title(f'Number of active features v.s. Adaptive penalty parameter mu with alpha={alpha}')\n",
    "#     plt.legend(loc=\"upper right\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot2 AUC_ROC v.s. attrN (for best score with the given attrN for GBFS) given alpha # for adaptive mu\n",
    "\n",
    "# GBFS_adaptive=collections.defaultdict(int)\n",
    "# for mu,alpha in model_results:\n",
    "#     for model in model_results[mu,alpha]:\n",
    "#         if model.topk==-1 and model.pen>0: \n",
    "#             GBFS_adaptive[model.attrN,alpha]=max(GBFS_adaptive[model.attrN,alpha],model.get_AUC())\n",
    "# for alpha in alphas:        \n",
    "#     plt.figure()\n",
    "#     lw = 2\n",
    "#     x2_axis=sorted([idx[0] for idx in GBFS_adaptive.keys() if idx[1]==alpha])\n",
    "#     y2_axis=[GBFS_adaptive[x,alpha] for x in x2_axis]\n",
    "#     plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "#              lw=lw, label='GBFS',marker=\"o\")\n",
    "#     plt.xlabel('number of active features')\n",
    "#     plt.ylabel('AUC_ROC scores')\n",
    "#     plt.title(f'AUC_ROC scores v.s. number of active features with alpha={alpha}')\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot3 precision @2 v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "# GBFS_adaptive=collections.defaultdict(int)\n",
    "# for mu,alpha in model_results:\n",
    "#     for model in model_results[mu,alpha]:\n",
    "#         GBFS_adaptive[model.attrN,alpha]=max(GBFS_adaptive[model.attrN,alpha],model.get_ranking_precision())\n",
    "# for alpha in alphas:        \n",
    "#     plt.figure()\n",
    "#     lw = 2\n",
    "#     x2_axis=sorted([idx[0] for idx in GBFS_adaptive.keys() if idx[1]==alpha])\n",
    "#     y2_axis=[GBFS_adaptive[x,alpha] for x in x2_axis]\n",
    "#     plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "#              lw=lw, label='GBFS',marker=\"o\")\n",
    "#     plt.xlabel('number of active features')\n",
    "#     plt.ylabel('ranking_precision scores')\n",
    "#     plt.title(f'ranking_precision scores v.s. number of active features with alpha={alpha}')\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot 4 precision@k v.s. k for three models that with <=25 variables\n",
    "# ks=[2,3,4,5]\n",
    "# GBFS_adaptive=collections.defaultdict(int)\n",
    "# for mu,alpha in model_results:\n",
    "#     for model in model_results[mu,alpha]:\n",
    "#         for k in ks:\n",
    "#             GBFS_adaptive[alpha,k]=max(GBFS_adaptive[alpha,k],model.get_ranking_precision(k=k))\n",
    "# for alpha in alphas:        \n",
    "#     plt.figure()\n",
    "#     lw = 2\n",
    "#     y2_axis=[GBFS_adaptive[alpha,k] for k in ks]\n",
    "#     plt.plot(ks, y2_axis, color='darkorange',\n",
    "#              lw=lw, label='GBFS',marker=\"o\")\n",
    "#     plt.xlabel('k as in precision @k')\n",
    "#     plt.ylabel('ranking_precision scores')\n",
    "#     plt.title(f'ranking_precision scores @k v.s. k with alpha={alpha}')\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot2 AUC_ROC v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "GBDTBTt=collections.defaultdict(int)\n",
    "GBFS_adaptive=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                GBDTt[model.attrN,alpha]=max(GBDTt[model.attrN,alpha],model.get_AUC())\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                GBDTBTt[model.attrN,alpha]=max(GBDTBTt[model.attrN,alpha],model.get_AUC())\n",
    "            elif model.topk==-1 and model.pen>1: \n",
    "                GBFS[model.attrN,alpha]=max(GBFS[model.attrN,alpha],model.get_AUC())\n",
    "            elif model.topk==-1 and model.pen>0:\n",
    "                GBFS_adaptive[model.attrN,alpha]=max(GBFS_adaptive[model.attrN,alpha],model.get_AUC())\n",
    "                \n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x1_axis=sorted([idx[0] for idx in GBDTt.keys() if idx[1]==alpha])\n",
    "    y1_axis=[GBDTt[x,alpha] for x in x1_axis]\n",
    "    x2_axis=sorted([idx[0] for idx in GBFS.keys() if idx[1]==alpha])\n",
    "    y2_axis=[GBFS[x,alpha] for x in x2_axis]\n",
    "    x3_axis=sorted([idx[0] for idx in GBDTBTt.keys() if idx[1]==alpha])\n",
    "    y3_axis=[GBDTBTt[x,alpha] for x in x3_axis]\n",
    "    x4_axis=sorted([idx[0] for idx in GBFS_adaptive.keys() if idx[1]==alpha])\n",
    "    y4_axis=[GBFS_adaptive[x,alpha] for x in x4_axis]\n",
    "    \n",
    "    plt.plot(x1_axis, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.plot(x3_axis, y3_axis, color='b',\n",
    "             lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "    plt.plot(x4_axis, y4_axis, color='r',\n",
    "             lw=lw, label='GBFS_adapt',marker=\"o\")\n",
    "    \n",
    "    #plt.ylim([0.93, 0.95])\n",
    "    plt.xlabel('number of active features')\n",
    "    plt.ylabel('AUC_ROC scores')\n",
    "    plt.title(f'AUC_ROC scores v.s. number of active features with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot3 precision @2 v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "GBDTBTt=collections.defaultdict(int)\n",
    "GBFS_adaptive=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                GBDTt[model.attrN,alpha]=max(GBDTt[model.attrN,alpha],model.get_ranking_precision())\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                GBDTBTt[model.attrN,alpha]=max(GBDTBTt[model.attrN,alpha],model.get_ranking_precision())\n",
    "            elif model.topk==-1 and model.pen>1: \n",
    "                GBFS[model.attrN,alpha]=max(GBFS[model.attrN,alpha],model.get_ranking_precision())\n",
    "            elif model.topk==-1 and model.pen>0:\n",
    "                GBFS_adaptive[model.attrN,alpha]=max(GBFS_adaptive[model.attrN,alpha],model.get_ranking_precision())\n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x1_axis=sorted([idx[0] for idx in GBDTt.keys() if idx[1]==alpha])\n",
    "    y1_axis=[GBDTt[x,alpha] for x in x1_axis]\n",
    "    x2_axis=sorted([idx[0] for idx in GBFS.keys() if idx[1]==alpha])\n",
    "    y2_axis=[GBFS[x,alpha] for x in x2_axis]\n",
    "    x3_axis=sorted([idx[0] for idx in GBDTBTt.keys() if idx[1]==alpha])\n",
    "    y3_axis=[GBDTBTt[x,alpha] for x in x3_axis]\n",
    "    x4_axis=sorted([idx[0] for idx in GBFS_adaptive.keys() if idx[1]==alpha])\n",
    "    y4_axis=[GBFS_adaptive[x,alpha] for x in x4_axis]\n",
    "    plt.plot(x1_axis, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.plot(x3_axis, y3_axis, color='b',\n",
    "             lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "    plt.plot(x4_axis, y4_axis, color='r',\n",
    "             lw=lw, label='GBFS_adapt',marker=\"o\")\n",
    "    plt.xlabel('number of active features')\n",
    "    plt.ylabel('ranking_precision scores')\n",
    "    plt.title(f'ranking_precision scores v.s. number of active features with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot3 precision @4 v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "GBDTBTt=collections.defaultdict(int)\n",
    "GBFS_adaptive=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                GBDTt[model.attrN,alpha]=max(GBDTt[model.attrN,alpha],model.get_ranking_precision(k=4))\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                GBDTBTt[model.attrN,alpha]=max(GBDTBTt[model.attrN,alpha],model.get_ranking_precision(k=4))\n",
    "            elif model.topk==-1 and model.pen>1: \n",
    "                GBFS[model.attrN,alpha]=max(GBFS[model.attrN,alpha],model.get_ranking_precision(k=4))\n",
    "            elif model.topk==-1 and model.pen>0:\n",
    "                GBFS_adaptive[model.attrN,alpha]=max(GBFS_adaptive[model.attrN,alpha],model.get_ranking_precision(k=4))\n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x1_axis=sorted([idx[0] for idx in GBDTt.keys() if idx[1]==alpha])\n",
    "    y1_axis=[GBDTt[x,alpha] for x in x1_axis]\n",
    "    x2_axis=sorted([idx[0] for idx in GBFS.keys() if idx[1]==alpha])\n",
    "    y2_axis=[GBFS[x,alpha] for x in x2_axis]\n",
    "    x3_axis=sorted([idx[0] for idx in GBDTBTt.keys() if idx[1]==alpha])\n",
    "    y3_axis=[GBDTBTt[x,alpha] for x in x3_axis]\n",
    "    x4_axis=sorted([idx[0] for idx in GBFS_adaptive.keys() if idx[1]==alpha])\n",
    "    y4_axis=[GBFS_adaptive[x,alpha] for x in x4_axis]\n",
    "    plt.plot(x1_axis, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.plot(x3_axis, y3_axis, color='b',\n",
    "             lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "    plt.plot(x4_axis, y4_axis, color='r',\n",
    "             lw=lw, label='GBFS_adapt',marker=\"o\")\n",
    "    plt.xlabel('number of active features')\n",
    "    plt.ylabel('ranking_precision scores')\n",
    "    plt.title(f'ranking_precision scores v.s. number of active features with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot3 precision @3 v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "GBDTBTt=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                GBDTt[model.attrN,alpha]=max(GBDTt[model.attrN,alpha],model.get_ranking_precision(k=3))\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                GBDTBTt[model.attrN,alpha]=max(GBDTBTt[model.attrN,alpha],model.get_ranking_precision(k=3))\n",
    "            elif model.topk==-1 and model.pen>0: \n",
    "                GBFS[model.attrN,alpha]=max(GBFS[model.attrN,alpha],model.get_ranking_precision(k=3))\n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x1_axis=sorted([idx[0] for idx in GBDTt.keys() if idx[1]==alpha])\n",
    "    y1_axis=[GBDTt[x,alpha] for x in x1_axis]\n",
    "    x2_axis=sorted([idx[0] for idx in GBFS.keys() if idx[1]==alpha])\n",
    "    y2_axis=[GBFS[x,alpha] for x in x2_axis]\n",
    "    x3_axis=sorted([idx[0] for idx in GBDTBTt.keys() if idx[1]==alpha])\n",
    "    y3_axis=[GBDTBTt[x,alpha] for x in x3_axis]\n",
    "    plt.plot(x1_axis, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.plot(x3_axis, y3_axis, color='b',\n",
    "             lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "    plt.xlabel('number of active features')\n",
    "    plt.ylabel('ranking_precision scores')\n",
    "    plt.title(f'ranking_precision scores v.s. number of active features with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot3 precision @5 v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "GBDTBTt=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                GBDTt[model.attrN,alpha]=max(GBDTt[model.attrN,alpha],model.get_ranking_precision(k=5))\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                GBDTBTt[model.attrN,alpha]=max(GBDTBTt[model.attrN,alpha],model.get_ranking_precision(k=5))\n",
    "            elif model.topk==-1 and model.pen>0: \n",
    "                GBFS[model.attrN,alpha]=max(GBFS[model.attrN,alpha],model.get_ranking_precision(k=5))\n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x1_axis=sorted([idx[0] for idx in GBDTt.keys() if idx[1]==alpha])\n",
    "    y1_axis=[GBDTt[x,alpha] for x in x1_axis]\n",
    "    x2_axis=sorted([idx[0] for idx in GBFS.keys() if idx[1]==alpha])\n",
    "    y2_axis=[GBFS[x,alpha] for x in x2_axis]\n",
    "    x3_axis=sorted([idx[0] for idx in GBDTBTt.keys() if idx[1]==alpha])\n",
    "    y3_axis=[GBDTBTt[x,alpha] for x in x3_axis]\n",
    "    plt.plot(x1_axis, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.plot(x3_axis, y3_axis, color='b',\n",
    "             lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "    plt.xlabel('number of active features')\n",
    "    plt.ylabel('ranking_precision scores')\n",
    "    plt.title(f'ranking_precision scores v.s. number of active features with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 4 precision@k v.s. k for three models that with <=25 variables\n",
    "ks=[2,3,4,5]\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "GBDTBTt=collections.defaultdict(int)\n",
    "GBFS_adaptive=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            for k in ks:\n",
    "                if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                    GBDTt[alpha,k]=max(GBDTt[alpha,k],model.get_ranking_precision(k=k))\n",
    "                elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                    GBDTBTt[alpha,k]=max(GBDTBTt[alpha,k],model.get_ranking_precision(k=k))\n",
    "                elif model.topk==-1 and model.pen>1: \n",
    "                    GBFS[alpha,k]=max(GBFS[alpha,k],model.get_ranking_precision(k=k))\n",
    "                elif model.topk==-1 and model.pen>0:\n",
    "                    GBFS_adaptive[alpha,k]=max(GBFS_adaptive[alpha,k],model.get_ranking_precision(k=k))\n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    y1_axis=[GBDTt[alpha,k] for k in ks]\n",
    "    y2_axis=[GBFS[alpha,k] for k in ks]\n",
    "    y3_axis=[GBDTBTt[alpha,k] for k in ks]\n",
    "    y4_axis=[GBFS_adaptive[alpha,k] for k in ks]\n",
    "    plt.plot(ks, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(ks, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.plot(ks, y3_axis, color='b',\n",
    "             lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "    plt.plot(ks, y4_axis, color='r',\n",
    "             lw=lw, label='GBFS_adapt',marker=\"o\")\n",
    "    plt.xlabel('k as in precision @k')\n",
    "    plt.ylabel('ranking_precision scores')\n",
    "    plt.title(f'ranking_precision scores @k v.s. k with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the best result for each model with attrN<=25 AUC\n",
    "gbdt_auc=[0,0,0,0] # AUC,attrN,pen,alpha\n",
    "gbdtbt_auc=[0,0,0,0]\n",
    "gbfs_auc=[0,0,0,0]\n",
    "gbfsad_auc=[0,0,0,0]\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                gbdt_auc=max(gbdt_auc,[model.get_AUC(),model.attrN,model.pen,model.alpha])\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                gbdtbt_auc=max(gbdtbt_auc,[model.get_AUC(),model.attrN,model.pen,model.alpha])\n",
    "            elif model.topk==-1 and model.pen>1: \n",
    "                gbfs_auc=max(gbfs_auc,[model.get_AUC(),model.attrN,model.pen,model.alpha])\n",
    "            elif model.topk==-1 and model.pen>0:\n",
    "                gbfsad_auc=max(gbfsad_auc,[model.get_AUC(),model.attrN,model.pen,model.alpha])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbdt_auc : [0.9128164257871372, 19, 0, 0.001]\n",
      "gbdtbt_auc : [0.9122246006485892, 17, 0, 0.01]\n",
      "gbfs_auc : [0.9141814665524568, 25, 14.0, 0.001]\n",
      "gbfsad_auc : [0.9117324537129279, 22, 0.15, 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(f\"gbdt_auc : {gbdt_auc}\")\n",
    "print(f\"gbdtbt_auc : {gbdtbt_auc}\")\n",
    "print(f\"gbfs_auc : {gbfs_auc}\")\n",
    "print(f\"gbfsad_auc : {gbfsad_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the best result for each model with attrN<=25 RMSE\n",
    "gbdt_rmse=[float(\"inf\"),0,0,0] # rmse,attrN,pen,alpha\n",
    "gbdtbt_rmse=[float(\"inf\"),0,0,0]\n",
    "gbfs_rmse=[float(\"inf\"),0,0,0]\n",
    "gbfsad_rmse=[float(\"inf\"),0,0,0]\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                gbdt_rmse=min(gbdt_rmse,[model.rmse,model.attrN,model.pen,model.alpha])\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                gbdtbt_rmse=min(gbdtbt_rmse,[model.rmse,model.attrN,model.pen,model.alpha])\n",
    "            elif model.topk==-1 and model.pen>1: \n",
    "                gbfs_rmse=min(gbfs_rmse,[model.rmse,model.attrN,model.pen,model.alpha])\n",
    "            elif model.topk==-1 and model.pen>0:\n",
    "                gbfsad_rmse=min(gbfsad_rmse,[model.rmse,model.attrN,model.pen,model.alpha])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbdt_rmse : [0.278256, 25, 0, 0.0]\n",
      "gbdtbt_rmse : [0.282011, 22, 0, 0.0]\n",
      "gbfs_rmse : [0.280356, 24, 19.0, 0.0]\n",
      "gbfsad_rmse : [0.289981, 22, 0.15, 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(f\"gbdt_rmse : {gbdt_rmse}\")\n",
    "print(f\"gbdtbt_rmse : {gbdtbt_rmse}\")\n",
    "print(f\"gbfs_rmse : {gbfs_rmse}\")\n",
    "print(f\"gbfsad_rmse : {gbfsad_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the best result for each model with attrN<=25 precision @k\n",
    "gbdt_prec={2:[0,0,0,0],3:[0,0,0,0],4:[0,0,0,0]}  # prec,attrN,pen,alpha\n",
    "gbdtbt_prec={2:[0,0,0,0],3:[0,0,0,0],4:[0,0,0,0]} \n",
    "gbfs_prec={2:[0,0,0,0],3:[0,0,0,0],4:[0,0,0,0]} \n",
    "gbfsad_prec={2:[0,0,0,0],3:[0,0,0,0],4:[0,0,0,0]} \n",
    "ks=[2,3,4]\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            for k in ks:\n",
    "                if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                    gbdt_prec[k]=max(gbdt_prec[k],[model.get_ranking_precision(k=k),model.attrN,model.pen,model.alpha])\n",
    "                elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                    gbdtbt_prec[k]=max(gbdtbt_prec[k],[model.get_ranking_precision(k=k),model.attrN,model.pen,model.alpha])\n",
    "                elif model.topk==-1 and model.pen>1: \n",
    "                    gbfs_prec[k]=max(gbfs_prec[k],[model.get_ranking_precision(k=k),model.attrN,model.pen,model.alpha])\n",
    "                elif model.topk==-1 and model.pen>0:\n",
    "                    gbfsad_prec[k]=max(gbfsad_prec[k],[model.get_ranking_precision(k=k),model.attrN,model.pen,model.alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"gbdt_prec : {gbdt_prec}\")\n",
    "print(f\"gbdtbt_prec : {gbdtbt_prec}\")\n",
    "print(f\"gbfs_prec : {gbfs_prec}\")\n",
    "print(f\"gbfsad_prec : {gbfsad_prec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for madelon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path='result/madelon/'\n",
    "attr_total=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess\n",
    "\n",
    "filenames_result=listdir(result_path)\n",
    "trueY=pd.read_csv(result_path+\"trueY.txt\",header=None)[0]\n",
    "#kw=pd.read_csv(result_path+\"keyword.txt\",header=None)[0]\n",
    "try:\n",
    "    number_unused=len(pd.read_csv(result_path+\"preprocess_unused.txt\",header=None))\n",
    "except:\n",
    "    number_unused=0\n",
    "attr_init_number=attr_total-number_unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results when go through all files in result folder\n",
    "# index result like [(mu,alpha)]\n",
    "GBFS_dict=collections.defaultdict(dict) # store preds,attrN for different mu and alpha\n",
    "GBDTt_dict={} # indexed by alpha,topk\n",
    "for filename in filenames_result:\n",
    "    last_dot=filename.rfind(\".\")\n",
    "    fname,fext=filename[:last_dot],filename[last_dot+1:]\n",
    "    if fext==\"txt\" and \"_alpha\" in fname:\n",
    "        alpha=float(fname[fname.index(\"_alpha\")+6:])\n",
    "        if \"_preds\" in fname:\n",
    "            preds=pd.read_csv(result_path+filename,header=None)[0]\n",
    "            if \"GBFSt\" in fname:\n",
    "                attrN=int(fname[5:fname.index(\"_mu\")])\n",
    "                GBDTt_dict[alpha,attrN]=preds\n",
    "            else:\n",
    "                idx=fname.index(\"_mu\")\n",
    "                mu=float(fname[idx+3:fname.index(\"_preds\")])\n",
    "                GBFS_dict[mu,alpha][\"preds\"]=preds\n",
    "        elif \"feature_scores_\" in fname:\n",
    "            tmp=pd.read_csv(result_path+filename,header=None)[0][0] # the first line of feature_score reports attrN\n",
    "            attrN=int(tmp.split()[-1])\n",
    "            if \"_mu\" in fname:\n",
    "                idx=fname.index(\"_mu\")\n",
    "                mu=float(fname[idx+3:fname.index(\"_alpha\")])\n",
    "            else:\n",
    "                mu=0\n",
    "            GBFS_dict[mu,alpha][\"attrN\"]=attrN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put result together\n",
    "model_results=collections.defaultdict(list) # indexed by mu,alpha\n",
    "# GBFS model\n",
    "for mu,alpha in GBFS_dict:\n",
    "    try:\n",
    "        attrN=GBFS_dict[mu,alpha][\"attrN\"]\n",
    "        preds=GBFS_dict[mu,alpha][\"preds\"]\n",
    "        model_results[mu,alpha].append(Model(penalty=mu,alpha=alpha,topk=-1,attrN=attrN,preds=preds))\n",
    "    except:\n",
    "        print(\"not ready\")\n",
    "# GBDTt model\n",
    "for alpha,topk in GBDTt_dict:\n",
    "    preds=GBDTt_dict[alpha,topk]\n",
    "    model_results[0,alpha].append(Model(alpha=alpha,topk=topk,attrN=topk,preds=preds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus=sorted(set(idx[0] for idx in GBFS_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=sorted(set(idx[1] for idx in GBFS_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot1 attrN v.s. mus for GBFS\n",
    "for alpha in alphas:\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x_axis=mus\n",
    "    y_axis=[GBFS_dict[mu,alpha][\"attrN\"] for mu in x_axis]\n",
    "    plt.plot(x_axis, y_axis, color='b',marker=\"o\",\n",
    "             lw=lw, label='GBFS')\n",
    "    #plt.xlim([0.0, max(x_axis)])\n",
    "    #plt.ylim([20, 100])\n",
    "    plt.xlabel('Penalty parameter mu')\n",
    "    plt.ylabel('Number of active features')\n",
    "    plt.title(f'Number of active features v.s. Penalty parameter mu with alpha={alpha}')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot2 AUC_ROC v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.pen==0 and model.topk>0:\n",
    "            GBDTt[model.attrN,alpha]=max(GBDTt[model.attrN,alpha],model.get_AUC())\n",
    "        elif model.topk==-1: \n",
    "            GBFS[model.attrN,alpha]=max(GBFS[model.attrN,alpha],model.get_AUC())\n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x1_axis=sorted([idx[0] for idx in GBDTt.keys() if idx[1]==alpha])\n",
    "    y1_axis=[GBDTt[x,alpha] for x in x1_axis]\n",
    "    x2_axis=sorted([idx[0] for idx in GBFS.keys() if idx[1]==alpha])\n",
    "    y2_axis=[GBFS[x,alpha] for x in x2_axis]\n",
    "    plt.plot(x1_axis, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.xlim([0,45])\n",
    "    #plt.ylim([0.93, 0.95])\n",
    "    plt.xlabel('number of active features')\n",
    "    plt.ylabel('AUC_ROC scores')\n",
    "    plt.title(f'AUC_ROC scores v.s. number of active features with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/cuize/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py:2785: DtypeWarning: Columns (14,17,82,103,126,161) have mixed types. Specify dtype option on import or set low_memory=False.\n",
      "  interactivity=interactivity, compiler=compiler, result=result)\n"
     ]
    }
   ],
   "source": [
    "# # us\n",
    "# train=pd.read_csv(\"data/us_train.tsv\",sep=\"\\t\")\n",
    "# GBFS=pd.read_csv(\"result/us/tuned/GBFS_model_feature_scores_mu8_alpha0.05_shrink0.1_itern100_attrn20_rms0.232841.txt\",header=None)[0]\n",
    "# GBDTBTt=pd.read_csv(\"result/us/tuned/GBDTBTt_feature_scores_mu0_alpha0.02_shrink0.05_itern200_attrn20_rms0.236866.txt\",header=None)[0]\n",
    "\n",
    "# cpod\n",
    "train=pd.read_csv(\"result/cpod/cpod_train.dta\",sep=\"\\t\",header=None)\n",
    "fs_attr=pd.read_csv(\"result/cpod/cpod_train.attr\",sep=\"\\t\",header=None)[0]\n",
    "GBFS=pd.read_csv(\"result/cpod/feature_scores_mu2.txt\",header=None)[0]\n",
    "GBDTBTt=pd.read_csv(\"result/cpod/BT_feature_scores.txt\",header=None)[0]\n",
    "\n",
    "# # baby\n",
    "# train=pd.read_csv(\"result/baby/baby_train.dta\",sep=\"\\t\",header=None)\n",
    "# fs_attr=pd.read_csv(\"result/baby/baby_train.attr\",sep=\"\\t\",header=None)[0]\n",
    "# GBFS=pd.read_csv(\"result/baby/feature_scores_mu8.txt\",header=None)[0]\n",
    "# GBDTBTt=pd.read_csv(\"result/baby/BT_feature_scores.txt\",header=None)[0]\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "# # us_fillna\n",
    "# train=pd.read_csv(\"data/us_train.tsv\",sep=\"\\t\")\n",
    "# GBFS=pd.read_csv(\"result/us/tuned/GBFS_model_feature_scores_mu8_alpha0.05_shrink0.1_itern100_attrn20_rms0.232841.txt\",header=None)[0]\n",
    "# GBDTBTt=pd.read_csv(\"result/us/tuned/GBDTBTt_feature_scores_mu0_alpha0.02_shrink0.05_itern200_attrn20_rms0.236866.txt\",header=None)[0]\n",
    "\n",
    "\n",
    "# # in\n",
    "# train=pd.read_csv(\"data/us_train.tsv\",sep=\"\\t\")\n",
    "# GBFS=pd.read_csv(\"result/us/tuned/GBFS_model_feature_scores_mu8_alpha0.05_shrink0.1_itern100_attrn20_rms0.232841.txt\",header=None)[0]\n",
    "# GBDTBTt=pd.read_csv(\"result/us/tuned/GBDTBTt_feature_scores_mu0_alpha0.02_shrink0.05_itern200_attrn20_rms0.236866.txt\",header=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for baby and cpod\n",
    "GBFS_f=[]\n",
    "GBDTBTt_f=[]\n",
    "for line in GBFS[2:22]:\n",
    "    tmp=line.split(\"\\t\")\n",
    "    if len(tmp)==2 and float(tmp[1])>0:\n",
    "        GBFS_f.append(tmp[0])\n",
    "for line in GBDTBTt[2:22]:\n",
    "    tmp=line.split(\"\\t\")\n",
    "    if len(tmp)==2 and float(tmp[1])>0:\n",
    "        GBDTBTt_f.append(tmp[0])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBFS_f=[]\n",
    "GBDTBTt_f=[]\n",
    "for line in GBFS[2:]:\n",
    "    tmp=line.split(\"\\t\")\n",
    "    if len(tmp)==2 and float(tmp[1])>0:\n",
    "        GBFS_f.append(tmp[0])\n",
    "for line in GBDTBTt[2:]:\n",
    "    tmp=line.split(\"\\t\")\n",
    "    if len(tmp)==2 and float(tmp[1])>0:\n",
    "        GBDTBTt_f.append(tmp[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'ab_decayed_num_clicks',\n",
       " 'length_normalized_termdoc',\n",
       " 'log_orders_decayed',\n",
       " 'nummatchbigrams_title_q',\n",
       " 'quer_count_phrasedoc',\n",
       " 'quer_max_phrasedoc',\n",
       " 'query_asin_aoea',\n",
       " 'query_asin_coec',\n",
       " 'query_asin_poep'}"
      ]
     },
     "execution_count": 178,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(GBFS_f).intersection(set(GBDTBTt_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for baby and cpod, convert column name to id\n",
    "GBFS_fid=[]\n",
    "GBDTBTt_fid=[]\n",
    "for i,ft in enumerate(fs_attr):\n",
    "    tmp=ft.split(\":\")\n",
    "    if len(tmp)==2:\n",
    "        tmp=tmp[0]\n",
    "        if tmp in GBFS_f:\n",
    "            GBFS_fid.append(i)\n",
    "        if tmp in GBDTBTt_f:\n",
    "            GBDTBTt_fid.append(i)\n",
    "GBDTBTt_f=GBDTBTt_fid\n",
    "GBFS_f=GBFS_fid"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBFS_f_cols=train[GBFS_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBDTBTt_f_cols=train[GBDTBTt_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 182,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBDTBTt_corr=GBDTBTt_f_cols.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 183,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBFS_corr=GBFS_f_cols.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBDTBTt_corr_spearman=GBDTBTt_f_cols.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBFS_corr_spearman=GBFS_f_cols.corr(method=\"spearman\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "62\n",
      "154\n",
      "154\n",
      "163\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "sums=0\n",
    "maxs=0\n",
    "abs_corrs_gbfs=[]\n",
    "for name in GBFS_corr:\n",
    "    for num in GBFS_corr[name]:\n",
    "        if not np.isnan(num) and num!=1:\n",
    "            if abs(num)>=0.9:\n",
    "                print(name)\n",
    "            abs_corrs_gbfs.append(abs(num))\n",
    "            maxs=max(maxs,abs(num))\n",
    "            sums+=abs(num)\n",
    "            cnt+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_corrs_gbfs.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_corr: 0.17766335565959926 max_abs_corr: 0.989102879099731\n"
     ]
    }
   ],
   "source": [
    "print(f'mean_corr: {sums/cnt} max_abs_corr: {maxs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "62\n",
      "62\n",
      "154\n",
      "154\n",
      "154\n",
      "163\n",
      "163\n",
      "163\n",
      "168\n",
      "168\n",
      "168\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "sums=0\n",
    "maxs=0\n",
    "abs_corrs_spearman_gbfs=[]\n",
    "for name in GBFS_corr_spearman:\n",
    "    for num in GBFS_corr_spearman[name]:\n",
    "        if not np.isnan(num) and num!=1:\n",
    "            if abs(num)>=0.9:\n",
    "                print(name)\n",
    "            abs_corrs_spearman_gbfs.append(abs(num))\n",
    "            maxs=max(maxs,abs(num))\n",
    "            sums+=abs(num)\n",
    "            cnt+=1        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_corrs_spearman_gbfs.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_corr: 0.23479342485531315 max_abs_corr: 0.9846192697922241\n"
     ]
    }
   ],
   "source": [
    "print(f'mean_corr: {sums/cnt} max_abs_corr: {maxs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "62\n",
      "154\n",
      "154\n",
      "163\n",
      "163\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "sums=0\n",
    "abs_corrs_gbdt=[]\n",
    "for name in GBDTBTt_corr:\n",
    "    for num in GBDTBTt_corr[name]:\n",
    "        if not np.isnan(num) and num!=1:\n",
    "            if abs(num)>0.9:\n",
    "                print(name)\n",
    "            abs_corrs_gbdt.append(abs(num))\n",
    "            maxs=max(maxs,abs(num))\n",
    "            sums+=abs(num)\n",
    "            cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_corrs_gbdt.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_corr: 0.17948408153866394 max_abs_corr: 0.989102879099731\n"
     ]
    }
   ],
   "source": [
    "print(f'mean_corr: {sums/cnt} max_abs_corr: {maxs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "62\n",
      "62\n",
      "62\n",
      "62\n",
      "154\n",
      "154\n",
      "154\n",
      "154\n",
      "163\n",
      "163\n",
      "163\n",
      "163\n",
      "174\n",
      "174\n",
      "174\n",
      "174\n",
      "176\n",
      "176\n",
      "176\n",
      "176\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "sums=0\n",
    "abs_corrs_spearman_gbdt=[]\n",
    "for name in GBDTBTt_corr_spearman:\n",
    "    for num in GBDTBTt_corr_spearman[name]:\n",
    "        if not np.isnan(num) and num!=1:\n",
    "            if abs(num)>0.9:\n",
    "                print(name)\n",
    "            abs_corrs_spearman_gbdt.append(abs(num))\n",
    "            maxs=max(maxs,abs(num))\n",
    "            sums+=abs(num)\n",
    "            cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_corrs_spearman_gbdt.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_corr: 0.22031511236036255 max_abs_corr: 0.989102879099731\n"
     ]
    }
   ],
   "source": [
    "print(f'mean_corr: {sums/cnt} max_abs_corr: {maxs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.989102879099731,\n",
       " 0.989102879099731,\n",
       " 0.986699535950672,\n",
       " 0.986699535950672,\n",
       " 0.9758566828330278,\n",
       " 0.9758566828330278,\n",
       " 0.87957590170839,\n",
       " 0.87957590170839,\n",
       " 0.8700701448087828,\n",
       " 0.8700701448087828,\n",
       " 0.8519623609314891,\n",
       " 0.8519623609314891,\n",
       " 0.8420015242949984,\n",
       " 0.8420015242949984,\n",
       " 0.8365010179852623,\n",
       " 0.8365010179852623,\n",
       " 0.815706720601175,\n",
       " 0.815706720601175,\n",
       " 0.8067814023095292,\n",
       " 0.8067814023095292,\n",
       " 0.7967460534720296,\n",
       " 0.7967460534720296,\n",
       " 0.733284757061011,\n",
       " 0.733284757061011,\n",
       " 0.6348611677559249,\n",
       " 0.6348611677559249,\n",
       " 0.6341603954074345,\n",
       " 0.6341603954074345,\n",
       " 0.6339285995260551,\n",
       " 0.6339285995260551,\n",
       " 0.5645755614589649,\n",
       " 0.5645755614589649,\n",
       " 0.5449233888241146,\n",
       " 0.5449233888241146,\n",
       " 0.5302532470653274,\n",
       " 0.5302532470653274,\n",
       " 0.4842103270518472,\n",
       " 0.4842103270518472,\n",
       " 0.4644752380209417,\n",
       " 0.4644752380209417,\n",
       " 0.46389823416010867,\n",
       " 0.46389823416010867,\n",
       " 0.46340209372817154,\n",
       " 0.46340209372817154,\n",
       " 0.4513380252005046,\n",
       " 0.4513380252005046,\n",
       " 0.4224070721037158,\n",
       " 0.4224070721037158,\n",
       " 0.41724514217397524,\n",
       " 0.41724514217397524,\n",
       " 0.4027012481207293,\n",
       " 0.4027012481207293,\n",
       " 0.39197183516425177,\n",
       " 0.39197183516425177,\n",
       " 0.39142788669498374,\n",
       " 0.39142788669498374,\n",
       " 0.3904005079013416,\n",
       " 0.3904005079013416,\n",
       " 0.3870537970749555,\n",
       " 0.3870537970749555,\n",
       " 0.38182135999604977,\n",
       " 0.38182135999604977,\n",
       " 0.34235824244601604,\n",
       " 0.34235824244601604,\n",
       " 0.3343704783070596,\n",
       " 0.3343704783070596,\n",
       " 0.333067277873566,\n",
       " 0.333067277873566,\n",
       " 0.32175822813680277,\n",
       " 0.32175822813680277,\n",
       " 0.3195900659447204,\n",
       " 0.3195900659447204,\n",
       " 0.31908828132996697,\n",
       " 0.31908828132996697,\n",
       " 0.3179492673557213,\n",
       " 0.3179492673557213,\n",
       " 0.30571489285623793,\n",
       " 0.30571489285623793,\n",
       " 0.30445088645467283,\n",
       " 0.30445088645467283,\n",
       " 0.3029917402732919,\n",
       " 0.3029917402732919,\n",
       " 0.25735028985178154,\n",
       " 0.25735028985178154,\n",
       " 0.2501949891308455,\n",
       " 0.2501949891308455,\n",
       " 0.23980987126459355,\n",
       " 0.23980987126459355,\n",
       " 0.23769357877320588,\n",
       " 0.23769357877320588,\n",
       " 0.23276317103312427,\n",
       " 0.23276317103312427,\n",
       " 0.22929985830690594,\n",
       " 0.22929985830690594,\n",
       " 0.22920059255634162,\n",
       " 0.22920059255634162,\n",
       " 0.22748159224875442,\n",
       " 0.22748159224875442,\n",
       " 0.22333280726017674,\n",
       " 0.22333280726017674,\n",
       " 0.22285159232027257,\n",
       " 0.22285159232027257,\n",
       " 0.22272763411389548,\n",
       " 0.22272763411389548,\n",
       " 0.2214293083486233,\n",
       " 0.2214293083486233,\n",
       " 0.20809045131458923,\n",
       " 0.20809045131458923,\n",
       " 0.20090255080862893,\n",
       " 0.20090255080862893,\n",
       " 0.1976481572450775,\n",
       " 0.1976481572450775,\n",
       " 0.1957153373998977,\n",
       " 0.1957153373998977,\n",
       " 0.19128332119032596,\n",
       " 0.19128332119032596,\n",
       " 0.1907055482310852,\n",
       " 0.1907055482310852,\n",
       " 0.18561104215017382,\n",
       " 0.18561104215017382,\n",
       " 0.17991185302192697,\n",
       " 0.17991185302192697,\n",
       " 0.17738805762455548,\n",
       " 0.17738805762455548,\n",
       " 0.17149807698109334,\n",
       " 0.17149807698109334,\n",
       " 0.15891315483571566,\n",
       " 0.15891315483571566,\n",
       " 0.14516212815251267,\n",
       " 0.14516212815251267,\n",
       " 0.1389727946433945,\n",
       " 0.1389727946433945,\n",
       " 0.1342224893069528,\n",
       " 0.1342224893069528,\n",
       " 0.1284350427398058,\n",
       " 0.1284350427398058,\n",
       " 0.12759735219525606,\n",
       " 0.12759735219525606,\n",
       " 0.12717397892938767,\n",
       " 0.12717397892938767,\n",
       " 0.12506849141869164,\n",
       " 0.12506849141869164,\n",
       " 0.12329576775396303,\n",
       " 0.12329576775396303,\n",
       " 0.12318776842950614,\n",
       " 0.12318776842950614,\n",
       " 0.12081855311454988,\n",
       " 0.12081855311454988,\n",
       " 0.12065478515304139,\n",
       " 0.12065478515304139,\n",
       " 0.11821075071865464,\n",
       " 0.11821075071865464,\n",
       " 0.11468290864722637,\n",
       " 0.11468290864722637,\n",
       " 0.11409155856139948,\n",
       " 0.11409155856139948,\n",
       " 0.11404913733612536,\n",
       " 0.11404913733612536,\n",
       " 0.11219186114991334,\n",
       " 0.11219186114991334,\n",
       " 0.11213020026610172,\n",
       " 0.11213020026610172,\n",
       " 0.112098277539182,\n",
       " 0.112098277539182,\n",
       " 0.10159460519230197,\n",
       " 0.10159460519230197,\n",
       " 0.09834029091447627,\n",
       " 0.09834029091447627,\n",
       " 0.09775056274210689,\n",
       " 0.09775056274210689,\n",
       " 0.0968942178025634,\n",
       " 0.0968942178025634,\n",
       " 0.09457066938979626,\n",
       " 0.09457066938979626,\n",
       " 0.09434906564435647,\n",
       " 0.09434906564435647,\n",
       " 0.09388659082521664,\n",
       " 0.09388659082521664,\n",
       " 0.09149915521875752,\n",
       " 0.09149915521875752,\n",
       " 0.08708620484392177,\n",
       " 0.08708620484392177,\n",
       " 0.08402209553464789,\n",
       " 0.08402209553464789,\n",
       " 0.08284185277565419,\n",
       " 0.08284185277565419,\n",
       " 0.08102408919026997,\n",
       " 0.08102408919026997,\n",
       " 0.07973690239068569,\n",
       " 0.07973690239068569,\n",
       " 0.07882673281719951,\n",
       " 0.07882673281719951,\n",
       " 0.07495698375629256,\n",
       " 0.07495698375629256,\n",
       " 0.0742012788784016,\n",
       " 0.0742012788784016,\n",
       " 0.07385991546652064,\n",
       " 0.07385991546652064,\n",
       " 0.07377584227440401,\n",
       " 0.07377584227440401,\n",
       " 0.07361331467215472,\n",
       " 0.07361331467215472,\n",
       " 0.07343370469687825,\n",
       " 0.07343370469687825,\n",
       " 0.07324548723727523,\n",
       " 0.07324548723727523,\n",
       " 0.07252559544225146,\n",
       " 0.07252559544225146,\n",
       " 0.07226652910303785,\n",
       " 0.07226652910303785,\n",
       " 0.07191451809823708,\n",
       " 0.07191451809823708,\n",
       " 0.0683745640851054,\n",
       " 0.0683745640851054,\n",
       " 0.06836838633297142,\n",
       " 0.06836838633297142,\n",
       " 0.06814454057766912,\n",
       " 0.06814454057766912,\n",
       " 0.06671232382500367,\n",
       " 0.06671232382500367,\n",
       " 0.0666792206640238,\n",
       " 0.0666792206640238,\n",
       " 0.06665310481492202,\n",
       " 0.06665310481492202,\n",
       " 0.06477950245241776,\n",
       " 0.06477950245241776,\n",
       " 0.06433700434659176,\n",
       " 0.06433700434659176,\n",
       " 0.06390074950145551,\n",
       " 0.06390074950145551,\n",
       " 0.0632765258796407,\n",
       " 0.0632765258796407,\n",
       " 0.06273674767200844,\n",
       " 0.06273674767200844,\n",
       " 0.05876505018281672,\n",
       " 0.05876505018281672,\n",
       " 0.0579171383393731,\n",
       " 0.0579171383393731,\n",
       " 0.05770683786128251,\n",
       " 0.05770683786128251,\n",
       " 0.0573569530661373,\n",
       " 0.0573569530661373,\n",
       " 0.056301805890728925,\n",
       " 0.056301805890728925,\n",
       " 0.05595943038837282,\n",
       " 0.05595943038837282,\n",
       " 0.05516128389584431,\n",
       " 0.05516128389584431,\n",
       " 0.05246949684588395,\n",
       " 0.05246949684588395,\n",
       " 0.05026484385249223,\n",
       " 0.05026484385249223,\n",
       " 0.05015175500330549,\n",
       " 0.05015175500330549,\n",
       " 0.05001122860064071,\n",
       " 0.05001122860064071,\n",
       " 0.04888574279031998,\n",
       " 0.04888574279031998,\n",
       " 0.04869977936414141,\n",
       " 0.04869977936414141,\n",
       " 0.04818220683901226,\n",
       " 0.04818220683901226,\n",
       " 0.04695250393589622,\n",
       " 0.04695250393589622,\n",
       " 0.046403739197334454,\n",
       " 0.046403739197334454,\n",
       " 0.044413138631509724,\n",
       " 0.044413138631509724,\n",
       " 0.04282285614706675,\n",
       " 0.04282285614706675,\n",
       " 0.04154225178262929,\n",
       " 0.04154225178262929,\n",
       " 0.0406165796345479,\n",
       " 0.0406165796345479,\n",
       " 0.040022339101833324,\n",
       " 0.040022339101833324,\n",
       " 0.03652019378254834,\n",
       " 0.03652019378254834,\n",
       " 0.03450869329821216,\n",
       " 0.03450869329821216,\n",
       " 0.0337410622934493,\n",
       " 0.0337410622934493,\n",
       " 0.03355336595291993,\n",
       " 0.03355336595291993,\n",
       " 0.03354385957217277,\n",
       " 0.03354385957217277,\n",
       " 0.032772925794187856,\n",
       " 0.032772925794187856,\n",
       " 0.0325329870297044,\n",
       " 0.0325329870297044,\n",
       " 0.032317799706228494,\n",
       " 0.032317799706228494,\n",
       " 0.026550362448490194,\n",
       " 0.026550362448490194,\n",
       " 0.026129896088754687,\n",
       " 0.026129896088754687,\n",
       " 0.024247373955808067,\n",
       " 0.024247373955808067,\n",
       " 0.022513370991133354,\n",
       " 0.022513370991133354,\n",
       " 0.02026659592867102,\n",
       " 0.02026659592867102,\n",
       " 0.019909100999755264,\n",
       " 0.019909100999755264,\n",
       " 0.019320457354184847,\n",
       " 0.019320457354184847,\n",
       " 0.01874868619972712,\n",
       " 0.01874868619972712,\n",
       " 0.016058574151681843,\n",
       " 0.016058574151681843,\n",
       " 0.015613710419617904,\n",
       " 0.015613710419617904,\n",
       " 0.014407945190256706,\n",
       " 0.014407945190256706,\n",
       " 0.012964968526103121,\n",
       " 0.012964968526103121,\n",
       " 0.012712883503968656,\n",
       " 0.012712883503968656,\n",
       " 0.011344518860142918,\n",
       " 0.011344518860142918,\n",
       " 0.008683752423228627,\n",
       " 0.008683752423228627,\n",
       " 0.008464171209606991,\n",
       " 0.008464171209606991,\n",
       " 0.007214491160444856,\n",
       " 0.007214491160444856,\n",
       " 0.007173819632800571,\n",
       " 0.007173819632800571,\n",
       " 0.006092473862523042,\n",
       " 0.006092473862523042,\n",
       " 0.006090226672156546,\n",
       " 0.006090226672156546,\n",
       " 0.004940803557677622,\n",
       " 0.004940803557677622,\n",
       " 0.004753734306843949,\n",
       " 0.004753734306843949,\n",
       " 0.004670496669507788,\n",
       " 0.004670496669507788,\n",
       " 0.003588744462850496,\n",
       " 0.003588744462850496,\n",
       " 0.003346597706172994,\n",
       " 0.003346597706172994,\n",
       " 0.0032162592506015234,\n",
       " 0.0032162592506015234,\n",
       " 0.0028832970148819875,\n",
       " 0.0028832970148819875,\n",
       " 0.002609528995283492,\n",
       " 0.002609528995283492,\n",
       " 0.002358986392603568,\n",
       " 0.002358986392603568,\n",
       " 0.0023416907099934616,\n",
       " 0.0023416907099934616,\n",
       " 0.0021433444792223044,\n",
       " 0.0021433444792223044,\n",
       " 0.0021432003340137954,\n",
       " 0.0021432003340137954,\n",
       " 0.0020359786265373115,\n",
       " 0.0020359786265373115,\n",
       " 0.0020271507705176793,\n",
       " 0.0020271507705176793,\n",
       " 0.001965637534360881,\n",
       " 0.001965637534360881,\n",
       " 0.0018950722856380543,\n",
       " 0.0018950722856380543,\n",
       " 0.0018310847284432148,\n",
       " 0.0018310847284432148,\n",
       " 0.001541430463063669,\n",
       " 0.001541430463063669,\n",
       " 0.0010429071433996412,\n",
       " 0.0010429071433996412,\n",
       " 0.0004484462207220388,\n",
       " 0.0004484462207220388,\n",
       " 0.0003271011162059583,\n",
       " 0.0003271011162059583,\n",
       " 0.0002718494871712154,\n",
       " 0.0002718494871712154,\n",
       " 0.00015816281438712593,\n",
       " 0.00015816281438712593,\n",
       " 0.00011973232638667547,\n",
       " 0.00011973232638667547]"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_corrs_gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9846192697922241,\n",
       " 0.9846192697922241,\n",
       " 0.9845410459996977,\n",
       " 0.9845410459996977,\n",
       " 0.9804089828701461,\n",
       " 0.9804089828701461,\n",
       " 0.9752861734282666,\n",
       " 0.9752861734282666,\n",
       " 0.975186999099523,\n",
       " 0.975186999099523,\n",
       " 0.9687895210816628,\n",
       " 0.9687895210816628,\n",
       " 0.964341782391562,\n",
       " 0.964341782391562,\n",
       " 0.9627548822876063,\n",
       " 0.9627548822876063,\n",
       " 0.9618750717401766,\n",
       " 0.9618750717401766,\n",
       " 0.9508436507798587,\n",
       " 0.9508436507798587,\n",
       " 0.8789877379992527,\n",
       " 0.8789877379992527,\n",
       " 0.7532135485117764,\n",
       " 0.7532135485117764,\n",
       " 0.7388490457017373,\n",
       " 0.7388490457017373,\n",
       " 0.7357040965902013,\n",
       " 0.7357040965902013,\n",
       " 0.7152472801761548,\n",
       " 0.7152472801761548,\n",
       " 0.6067205279194183,\n",
       " 0.6067205279194183,\n",
       " 0.6054255793127183,\n",
       " 0.6054255793127183,\n",
       " 0.6019609535905257,\n",
       " 0.6019609535905257,\n",
       " 0.5883590980899884,\n",
       " 0.5883590980899884,\n",
       " 0.5850374993852571,\n",
       " 0.5850374993852571,\n",
       " 0.5812801165203015,\n",
       " 0.5812801165203015,\n",
       " 0.5319496330892646,\n",
       " 0.5319496330892646,\n",
       " 0.529302642715784,\n",
       " 0.529302642715784,\n",
       " 0.51873543310554,\n",
       " 0.51873543310554,\n",
       " 0.5175225728319743,\n",
       " 0.5175225728319743,\n",
       " 0.5118699166287197,\n",
       " 0.5118699166287197,\n",
       " 0.5069554959821777,\n",
       " 0.5069554959821777,\n",
       " 0.5022916181763263,\n",
       " 0.5022916181763263,\n",
       " 0.5010145592919534,\n",
       " 0.5010145592919534,\n",
       " 0.5004073496671972,\n",
       " 0.5004073496671972,\n",
       " 0.49961907887934215,\n",
       " 0.49961907887934215,\n",
       " 0.46912223312439577,\n",
       " 0.46912223312439577,\n",
       " 0.46810434612360613,\n",
       " 0.46810434612360613,\n",
       " 0.46389395402548633,\n",
       " 0.46389395402548633,\n",
       " 0.4637431301681787,\n",
       " 0.4637431301681787,\n",
       " 0.46131558682792373,\n",
       " 0.46131558682792373,\n",
       " 0.46103408110288424,\n",
       " 0.46103408110288424,\n",
       " 0.45471503307462624,\n",
       " 0.45471503307462624,\n",
       " 0.45281376787348404,\n",
       " 0.45281376787348404,\n",
       " 0.4489958866592013,\n",
       " 0.4489958866592013,\n",
       " 0.4434406174846865,\n",
       " 0.4434406174846865,\n",
       " 0.4403093357289544,\n",
       " 0.4403093357289544,\n",
       " 0.4260119988380393,\n",
       " 0.4260119988380393,\n",
       " 0.421892077939523,\n",
       " 0.421892077939523,\n",
       " 0.42010667889157605,\n",
       " 0.42010667889157605,\n",
       " 0.3643617212067378,\n",
       " 0.3643617212067378,\n",
       " 0.3124869406520535,\n",
       " 0.3124869406520535,\n",
       " 0.28656516061865067,\n",
       " 0.28656516061865067,\n",
       " 0.2858406242389024,\n",
       " 0.2858406242389024,\n",
       " 0.28563551294905265,\n",
       " 0.28563551294905265,\n",
       " 0.2727109786602926,\n",
       " 0.2727109786602926,\n",
       " 0.2686317446274253,\n",
       " 0.2686317446274253,\n",
       " 0.2633326773899164,\n",
       " 0.2633326773899164,\n",
       " 0.24264612865216814,\n",
       " 0.24264612865216814,\n",
       " 0.229043995517625,\n",
       " 0.229043995517625,\n",
       " 0.21765150368797773,\n",
       " 0.21765150368797773,\n",
       " 0.21655740433122872,\n",
       " 0.21655740433122872,\n",
       " 0.21424021088784154,\n",
       " 0.21424021088784154,\n",
       " 0.21272256213858273,\n",
       " 0.21272256213858273,\n",
       " 0.2116159937158954,\n",
       " 0.2116159937158954,\n",
       " 0.2082826583830909,\n",
       " 0.2082826583830909,\n",
       " 0.2054825630320795,\n",
       " 0.2054825630320795,\n",
       " 0.20531821925033733,\n",
       " 0.20531821925033733,\n",
       " 0.20356626468237887,\n",
       " 0.20356626468237887,\n",
       " 0.20225364818864378,\n",
       " 0.20225364818864378,\n",
       " 0.19691135344986613,\n",
       " 0.19691135344986613,\n",
       " 0.1943405334797807,\n",
       " 0.1943405334797807,\n",
       " 0.1926061586916169,\n",
       " 0.1926061586916169,\n",
       " 0.16604136576703812,\n",
       " 0.16604136576703812,\n",
       " 0.16576678497404004,\n",
       " 0.16576678497404004,\n",
       " 0.16558838203877677,\n",
       " 0.16558838203877677,\n",
       " 0.15820939821498087,\n",
       " 0.15820939821498087,\n",
       " 0.15731738734407275,\n",
       " 0.15731738734407275,\n",
       " 0.15715605542286418,\n",
       " 0.15715605542286418,\n",
       " 0.14375394728130078,\n",
       " 0.14375394728130078,\n",
       " 0.13990457778052728,\n",
       " 0.13990457778052728,\n",
       " 0.13866962987399706,\n",
       " 0.13866962987399706,\n",
       " 0.1330097869167616,\n",
       " 0.1330097869167616,\n",
       " 0.11726762330363641,\n",
       " 0.11726762330363641,\n",
       " 0.11717296189752517,\n",
       " 0.11717296189752517,\n",
       " 0.11671529430952492,\n",
       " 0.11671529430952492,\n",
       " 0.116438609577113,\n",
       " 0.116438609577113,\n",
       " 0.1153962354777799,\n",
       " 0.1153962354777799,\n",
       " 0.11534973203154497,\n",
       " 0.11534973203154497,\n",
       " 0.11400928953506456,\n",
       " 0.11400928953506456,\n",
       " 0.11015493000644914,\n",
       " 0.11015493000644914,\n",
       " 0.1098412153358869,\n",
       " 0.1098412153358869,\n",
       " 0.10483778616836205,\n",
       " 0.10483778616836205,\n",
       " 0.10358501075953754,\n",
       " 0.10358501075953754,\n",
       " 0.10310111684697665,\n",
       " 0.10310111684697665,\n",
       " 0.09649063844984103,\n",
       " 0.09649063844984103,\n",
       " 0.08690549942383773,\n",
       " 0.08690549942383773,\n",
       " 0.08615613297581656,\n",
       " 0.08615613297581656,\n",
       " 0.08494523523031856,\n",
       " 0.08494523523031856,\n",
       " 0.08359162406726604,\n",
       " 0.08359162406726604,\n",
       " 0.08328189866320461,\n",
       " 0.08328189866320461,\n",
       " 0.08298940842755737,\n",
       " 0.08298940842755737,\n",
       " 0.08203579421580041,\n",
       " 0.08203579421580041,\n",
       " 0.08191543603834281,\n",
       " 0.08191543603834281,\n",
       " 0.08087266919636978,\n",
       " 0.08087266919636978,\n",
       " 0.08037724005253638,\n",
       " 0.08037724005253638,\n",
       " 0.0786207107265639,\n",
       " 0.0786207107265639,\n",
       " 0.07806908722615158,\n",
       " 0.07806908722615158,\n",
       " 0.07740276283762883,\n",
       " 0.07740276283762883,\n",
       " 0.07729347161011928,\n",
       " 0.07729347161011928,\n",
       " 0.07509130982112933,\n",
       " 0.07509130982112933,\n",
       " 0.07482165777085553,\n",
       " 0.07482165777085553,\n",
       " 0.07472982268067555,\n",
       " 0.07472982268067555,\n",
       " 0.07426577718023823,\n",
       " 0.07426577718023823,\n",
       " 0.07416089417639209,\n",
       " 0.07416089417639209,\n",
       " 0.07391864609581751,\n",
       " 0.07391864609581751,\n",
       " 0.07377870098530896,\n",
       " 0.07377870098530896,\n",
       " 0.0737614394264867,\n",
       " 0.0737614394264867,\n",
       " 0.07365687122445112,\n",
       " 0.07365687122445112,\n",
       " 0.07364239171795718,\n",
       " 0.07364239171795718,\n",
       " 0.07222661749277827,\n",
       " 0.07222661749277827,\n",
       " 0.07205850043100347,\n",
       " 0.07205850043100347,\n",
       " 0.07133186557288314,\n",
       " 0.07133186557288314,\n",
       " 0.07120646522641334,\n",
       " 0.07120646522641334,\n",
       " 0.07050234602997513,\n",
       " 0.07050234602997513,\n",
       " 0.06977261752407345,\n",
       " 0.06977261752407345,\n",
       " 0.06974673986221504,\n",
       " 0.06974673986221504,\n",
       " 0.06902281032474933,\n",
       " 0.06902281032474933,\n",
       " 0.06839790828455275,\n",
       " 0.06839790828455275,\n",
       " 0.06823169341867603,\n",
       " 0.06823169341867603,\n",
       " 0.06807927671999801,\n",
       " 0.06807927671999801,\n",
       " 0.06716379753631649,\n",
       " 0.06716379753631649,\n",
       " 0.06653445397749778,\n",
       " 0.06653445397749778,\n",
       " 0.06651669741102204,\n",
       " 0.06651669741102204,\n",
       " 0.06554377944401393,\n",
       " 0.06554377944401393,\n",
       " 0.0653731917028739,\n",
       " 0.0653731917028739,\n",
       " 0.06502437543687097,\n",
       " 0.06502437543687097,\n",
       " 0.06346161812280171,\n",
       " 0.06346161812280171,\n",
       " 0.06316904181303644,\n",
       " 0.06316904181303644,\n",
       " 0.06308332995556656,\n",
       " 0.06308332995556656,\n",
       " 0.06223079162006362,\n",
       " 0.06223079162006362,\n",
       " 0.059512630838015196,\n",
       " 0.059512630838015196,\n",
       " 0.05931147870578469,\n",
       " 0.05931147870578469,\n",
       " 0.059109864482061,\n",
       " 0.059109864482061,\n",
       " 0.05638884791636202,\n",
       " 0.05638884791636202,\n",
       " 0.05600978361042755,\n",
       " 0.05600978361042755,\n",
       " 0.05567929155446311,\n",
       " 0.05567929155446311,\n",
       " 0.05499853320694488,\n",
       " 0.05499853320694488,\n",
       " 0.05489114634899826,\n",
       " 0.05489114634899826,\n",
       " 0.054413852578703,\n",
       " 0.054413852578703,\n",
       " 0.05434367298976374,\n",
       " 0.05434367298976374,\n",
       " 0.053063154644694556,\n",
       " 0.053063154644694556,\n",
       " 0.0526731048800201,\n",
       " 0.0526731048800201,\n",
       " 0.052067101282468845,\n",
       " 0.052067101282468845,\n",
       " 0.050010548365970034,\n",
       " 0.050010548365970034,\n",
       " 0.04677686545226045,\n",
       " 0.04677686545226045,\n",
       " 0.04460972048559616,\n",
       " 0.04460972048559616,\n",
       " 0.04448504245859141,\n",
       " 0.04448504245859141,\n",
       " 0.04400584976496803,\n",
       " 0.04400584976496803,\n",
       " 0.040624577230031864,\n",
       " 0.040624577230031864,\n",
       " 0.040558684850146395,\n",
       " 0.040558684850146395,\n",
       " 0.03878384742832015,\n",
       " 0.03878384742832015,\n",
       " 0.03777088159706086,\n",
       " 0.03777088159706086,\n",
       " 0.031885311678315764,\n",
       " 0.031885311678315764,\n",
       " 0.028797807158713717,\n",
       " 0.028797807158713717,\n",
       " 0.02465524801598523,\n",
       " 0.02465524801598523,\n",
       " 0.02456884656407699,\n",
       " 0.02456884656407699,\n",
       " 0.024076209809660326,\n",
       " 0.024076209809660326,\n",
       " 0.022894294609688042,\n",
       " 0.022894294609688042,\n",
       " 0.022479971370730694,\n",
       " 0.022479971370730694,\n",
       " 0.021662591670703623,\n",
       " 0.021662591670703623,\n",
       " 0.021123296852327153,\n",
       " 0.021123296852327153,\n",
       " 0.021042525453931378,\n",
       " 0.021042525453931378,\n",
       " 0.02036465672170391,\n",
       " 0.02036465672170391,\n",
       " 0.019678459266555294,\n",
       " 0.019678459266555294,\n",
       " 0.019233896495271414,\n",
       " 0.019233896495271414,\n",
       " 0.018249618632667632,\n",
       " 0.018249618632667632,\n",
       " 0.0171483624516752,\n",
       " 0.0171483624516752,\n",
       " 0.016033261027209488,\n",
       " 0.016033261027209488,\n",
       " 0.015936590473655324,\n",
       " 0.015936590473655324,\n",
       " 0.014890437374850952,\n",
       " 0.014890437374850952,\n",
       " 0.014670864628282073,\n",
       " 0.014670864628282073,\n",
       " 0.011277592979862743,\n",
       " 0.011277592979862743,\n",
       " 0.01051349230676252,\n",
       " 0.01051349230676252,\n",
       " 0.008764512324249345,\n",
       " 0.008764512324249345,\n",
       " 0.008709189506017144,\n",
       " 0.008709189506017144,\n",
       " 0.006743226031889633,\n",
       " 0.006743226031889633,\n",
       " 0.0060924738629036974,\n",
       " 0.0060924738629036974,\n",
       " 0.005184375035216253,\n",
       " 0.005184375035216253,\n",
       " 0.004748393529961712,\n",
       " 0.004748393529961712,\n",
       " 0.004687252072757656,\n",
       " 0.004687252072757656,\n",
       " 0.0028477699581554244,\n",
       " 0.0028477699581554244,\n",
       " 0.0011156210903415433,\n",
       " 0.0011156210903415433,\n",
       " 0.0008034304808455767,\n",
       " 0.0008034304808455767,\n",
       " 0.0007586794393919145,\n",
       " 0.0007586794393919145]"
      ]
     },
     "execution_count": 223,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_corrs_spearman_gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.989102879099731,\n",
       " 0.989102879099731,\n",
       " 0.986699535950672,\n",
       " 0.986699535950672,\n",
       " 0.9758566828330278,\n",
       " 0.9758566828330278,\n",
       " 0.8711578449526707,\n",
       " 0.8711578449526707,\n",
       " 0.8596824722990417,\n",
       " 0.8596824722990417,\n",
       " 0.8495221352560396,\n",
       " 0.8495221352560396,\n",
       " 0.796427406593832,\n",
       " 0.796427406593832,\n",
       " 0.7920583339429383,\n",
       " 0.7920583339429383,\n",
       " 0.7860485084809197,\n",
       " 0.7860485084809197,\n",
       " 0.6797624941164135,\n",
       " 0.6797624941164135,\n",
       " 0.6513856127124097,\n",
       " 0.6513856127124097,\n",
       " 0.6497658528000243,\n",
       " 0.6497658528000243,\n",
       " 0.6348611677559249,\n",
       " 0.6348611677559249,\n",
       " 0.6346678697830926,\n",
       " 0.6346678697830926,\n",
       " 0.6341603954074345,\n",
       " 0.6341603954074345,\n",
       " 0.6339285995260551,\n",
       " 0.6339285995260551,\n",
       " 0.6323658410205005,\n",
       " 0.6323658410205005,\n",
       " 0.5998780969862364,\n",
       " 0.5998780969862364,\n",
       " 0.5540707118697351,\n",
       " 0.5540707118697351,\n",
       " 0.5273623203224552,\n",
       " 0.5273623203224552,\n",
       " 0.4842103270518472,\n",
       " 0.4842103270518472,\n",
       " 0.42454945552922607,\n",
       " 0.42454945552922607,\n",
       " 0.4224070721037158,\n",
       " 0.4224070721037158,\n",
       " 0.41724514217397524,\n",
       " 0.41724514217397524,\n",
       " 0.39197183516425177,\n",
       " 0.39197183516425177,\n",
       " 0.39165135253056155,\n",
       " 0.39165135253056155,\n",
       " 0.3904005079013416,\n",
       " 0.3904005079013416,\n",
       " 0.3876824021623286,\n",
       " 0.3876824021623286,\n",
       " 0.3870537970749555,\n",
       " 0.3870537970749555,\n",
       " 0.3826801092968982,\n",
       " 0.3826801092968982,\n",
       " 0.3638052931994582,\n",
       " 0.3638052931994582,\n",
       " 0.3631925447264156,\n",
       " 0.3631925447264156,\n",
       " 0.3620333044873316,\n",
       " 0.3620333044873316,\n",
       " 0.36177812621092764,\n",
       " 0.36177812621092764,\n",
       " 0.3471267579810176,\n",
       " 0.3471267579810176,\n",
       " 0.34286870429440164,\n",
       " 0.34286870429440164,\n",
       " 0.33960926126479524,\n",
       " 0.33960926126479524,\n",
       " 0.33474561669173414,\n",
       " 0.33474561669173414,\n",
       " 0.333082782700581,\n",
       " 0.333082782700581,\n",
       " 0.32885208438489116,\n",
       " 0.32885208438489116,\n",
       " 0.3233283368015676,\n",
       " 0.3233283368015676,\n",
       " 0.32175822813680277,\n",
       " 0.32175822813680277,\n",
       " 0.3195900659447204,\n",
       " 0.3195900659447204,\n",
       " 0.3179492673557213,\n",
       " 0.3179492673557213,\n",
       " 0.3095356004037967,\n",
       " 0.3095356004037967,\n",
       " 0.29743833307764955,\n",
       " 0.29743833307764955,\n",
       " 0.27148383936674686,\n",
       " 0.27148383936674686,\n",
       " 0.26308919884548976,\n",
       " 0.26308919884548976,\n",
       " 0.25817403213111817,\n",
       " 0.25817403213111817,\n",
       " 0.23728568531802108,\n",
       " 0.23728568531802108,\n",
       " 0.23276317103312427,\n",
       " 0.23276317103312427,\n",
       " 0.22929985830690594,\n",
       " 0.22929985830690594,\n",
       " 0.22920059255634162,\n",
       " 0.22920059255634162,\n",
       " 0.22748159224875442,\n",
       " 0.22748159224875442,\n",
       " 0.22268982286775832,\n",
       " 0.22268982286775832,\n",
       " 0.20014869730350776,\n",
       " 0.20014869730350776,\n",
       " 0.1847902752393281,\n",
       " 0.1847902752393281,\n",
       " 0.17908664905665117,\n",
       " 0.17908664905665117,\n",
       " 0.1758423553431512,\n",
       " 0.1758423553431512,\n",
       " 0.17154008668962029,\n",
       " 0.17154008668962029,\n",
       " 0.16645669993907208,\n",
       " 0.16645669993907208,\n",
       " 0.16095513225964472,\n",
       " 0.16095513225964472,\n",
       " 0.1509422008672181,\n",
       " 0.1509422008672181,\n",
       " 0.1428105129318182,\n",
       " 0.1428105129318182,\n",
       " 0.1389727946433945,\n",
       " 0.1389727946433945,\n",
       " 0.13793347392015196,\n",
       " 0.13793347392015196,\n",
       " 0.1342224893069528,\n",
       " 0.1342224893069528,\n",
       " 0.1284350427398058,\n",
       " 0.1284350427398058,\n",
       " 0.12712661688761304,\n",
       " 0.12712661688761304,\n",
       " 0.12668439182171826,\n",
       " 0.12668439182171826,\n",
       " 0.1246253548285276,\n",
       " 0.1246253548285276,\n",
       " 0.12234202132418324,\n",
       " 0.12234202132418324,\n",
       " 0.12081855311454988,\n",
       " 0.12081855311454988,\n",
       " 0.1164643234073583,\n",
       " 0.1164643234073583,\n",
       " 0.11192027388704591,\n",
       " 0.11192027388704591,\n",
       " 0.10796791185756988,\n",
       " 0.10796791185756988,\n",
       " 0.09861147083680813,\n",
       " 0.09861147083680813,\n",
       " 0.09644050411963956,\n",
       " 0.09644050411963956,\n",
       " 0.09149915521875752,\n",
       " 0.09149915521875752,\n",
       " 0.08527687822548664,\n",
       " 0.08527687822548664,\n",
       " 0.08328535567194219,\n",
       " 0.08328535567194219,\n",
       " 0.08293888292317847,\n",
       " 0.08293888292317847,\n",
       " 0.08253626627669726,\n",
       " 0.08253626627669726,\n",
       " 0.08237730383195915,\n",
       " 0.08237730383195915,\n",
       " 0.0821615507472671,\n",
       " 0.0821615507472671,\n",
       " 0.08164132558128367,\n",
       " 0.08164132558128367,\n",
       " 0.08107235763898786,\n",
       " 0.08107235763898786,\n",
       " 0.08106020406612859,\n",
       " 0.08106020406612859,\n",
       " 0.07973690239068569,\n",
       " 0.07973690239068569,\n",
       " 0.0783075590903787,\n",
       " 0.0783075590903787,\n",
       " 0.07484403397034038,\n",
       " 0.07484403397034038,\n",
       " 0.07466889067530143,\n",
       " 0.07466889067530143,\n",
       " 0.07355020466909888,\n",
       " 0.07355020466909888,\n",
       " 0.07266372362106976,\n",
       " 0.07266372362106976,\n",
       " 0.07192715671831938,\n",
       " 0.07192715671831938,\n",
       " 0.06890732190415255,\n",
       " 0.06890732190415255,\n",
       " 0.0683745640851054,\n",
       " 0.0683745640851054,\n",
       " 0.06814190699888378,\n",
       " 0.06814190699888378,\n",
       " 0.0655405135102044,\n",
       " 0.0655405135102044,\n",
       " 0.06493165155409479,\n",
       " 0.06493165155409479,\n",
       " 0.06427567018578256,\n",
       " 0.06427567018578256,\n",
       " 0.06273674767200844,\n",
       " 0.06273674767200844,\n",
       " 0.061190535221707185,\n",
       " 0.061190535221707185,\n",
       " 0.05923118872691984,\n",
       " 0.05923118872691984,\n",
       " 0.059219547255565545,\n",
       " 0.059219547255565545,\n",
       " 0.05876505018281672,\n",
       " 0.05876505018281672,\n",
       " 0.05770683786128251,\n",
       " 0.05770683786128251,\n",
       " 0.05763563273909565,\n",
       " 0.05763563273909565,\n",
       " 0.055409282606917326,\n",
       " 0.055409282606917326,\n",
       " 0.054912317021767784,\n",
       " 0.054912317021767784,\n",
       " 0.05415244350720197,\n",
       " 0.05415244350720197,\n",
       " 0.0538980792359778,\n",
       " 0.0538980792359778,\n",
       " 0.05043099610994792,\n",
       " 0.05043099610994792,\n",
       " 0.05015175500330549,\n",
       " 0.05015175500330549,\n",
       " 0.04872176918293325,\n",
       " 0.04872176918293325,\n",
       " 0.04854030864386607,\n",
       " 0.04854030864386607,\n",
       " 0.04734949014871148,\n",
       " 0.04734949014871148,\n",
       " 0.04663330520472356,\n",
       " 0.04663330520472356,\n",
       " 0.04463337439688039,\n",
       " 0.04463337439688039,\n",
       " 0.042324887670008374,\n",
       " 0.042324887670008374,\n",
       " 0.041897147775032235,\n",
       " 0.041897147775032235,\n",
       " 0.041560887843683524,\n",
       " 0.041560887843683524,\n",
       " 0.04117569565522043,\n",
       " 0.04117569565522043,\n",
       " 0.0406165796345479,\n",
       " 0.0406165796345479,\n",
       " 0.03892134737831239,\n",
       " 0.03892134737831239,\n",
       " 0.03881488510993536,\n",
       " 0.03881488510993536,\n",
       " 0.03837167292664004,\n",
       " 0.03837167292664004,\n",
       " 0.03836440225726818,\n",
       " 0.03836440225726818,\n",
       " 0.0379615873158382,\n",
       " 0.0379615873158382,\n",
       " 0.03698859631768875,\n",
       " 0.03698859631768875,\n",
       " 0.03675196830972295,\n",
       " 0.03675196830972295,\n",
       " 0.03652476877336324,\n",
       " 0.03652476877336324,\n",
       " 0.0364913423359466,\n",
       " 0.0364913423359466,\n",
       " 0.03627057880394277,\n",
       " 0.03627057880394277,\n",
       " 0.035929959075058894,\n",
       " 0.035929959075058894,\n",
       " 0.035793492739790954,\n",
       " 0.035793492739790954,\n",
       " 0.03560660095313576,\n",
       " 0.03560660095313576,\n",
       " 0.03483803863358622,\n",
       " 0.03483803863358622,\n",
       " 0.03425938849790289,\n",
       " 0.03425938849790289,\n",
       " 0.032772925794187856,\n",
       " 0.032772925794187856,\n",
       " 0.03207112486220071,\n",
       " 0.03207112486220071,\n",
       " 0.03169110679837354,\n",
       " 0.03169110679837354,\n",
       " 0.029321905745580436,\n",
       " 0.029321905745580436,\n",
       " 0.0285912930711032,\n",
       " 0.0285912930711032,\n",
       " 0.0270231482574295,\n",
       " 0.0270231482574295,\n",
       " 0.025951749800943027,\n",
       " 0.025951749800943027,\n",
       " 0.0254881836746266,\n",
       " 0.0254881836746266,\n",
       " 0.025364228709355435,\n",
       " 0.025364228709355435,\n",
       " 0.025027835830712775,\n",
       " 0.025027835830712775,\n",
       " 0.024247373955808067,\n",
       " 0.024247373955808067,\n",
       " 0.023962135590129052,\n",
       " 0.023962135590129052,\n",
       " 0.0228973330964513,\n",
       " 0.0228973330964513,\n",
       " 0.02089503662206725,\n",
       " 0.02089503662206725,\n",
       " 0.02085311125685863,\n",
       " 0.02085311125685863,\n",
       " 0.01874868619972712,\n",
       " 0.01874868619972712,\n",
       " 0.016817118697156578,\n",
       " 0.016817118697156578,\n",
       " 0.016058574151681843,\n",
       " 0.016058574151681843,\n",
       " 0.01601561390554144,\n",
       " 0.01601561390554144,\n",
       " 0.015606214856300179,\n",
       " 0.015606214856300179,\n",
       " 0.015224299271522483,\n",
       " 0.015224299271522483,\n",
       " 0.0151694588380456,\n",
       " 0.0151694588380456,\n",
       " 0.014875438677553029,\n",
       " 0.014875438677553029,\n",
       " 0.014333844406235795,\n",
       " 0.014333844406235795,\n",
       " 0.013873748658657429,\n",
       " 0.013873748658657429,\n",
       " 0.01302964558494962,\n",
       " 0.01302964558494962,\n",
       " 0.010742640336296825,\n",
       " 0.010742640336296825,\n",
       " 0.00968893044956865,\n",
       " 0.00968893044956865,\n",
       " 0.00950651192188801,\n",
       " 0.00950651192188801,\n",
       " 0.00947456483052145,\n",
       " 0.00947456483052145,\n",
       " 0.009296161151506431,\n",
       " 0.009296161151506431,\n",
       " 0.008645481334120221,\n",
       " 0.008645481334120221,\n",
       " 0.007214491160444856,\n",
       " 0.007214491160444856,\n",
       " 0.006244213895818314,\n",
       " 0.006244213895818314,\n",
       " 0.006114072179777636,\n",
       " 0.006114072179777636,\n",
       " 0.005353570980985485,\n",
       " 0.005353570980985485,\n",
       " 0.0050611291505381325,\n",
       " 0.0050611291505381325,\n",
       " 0.004759935520222075,\n",
       " 0.004759935520222075,\n",
       " 0.004548831072513695,\n",
       " 0.004548831072513695,\n",
       " 0.004250928005209367,\n",
       " 0.004250928005209367,\n",
       " 0.003580297705860744,\n",
       " 0.003580297705860744,\n",
       " 0.003311837558254791,\n",
       " 0.003311837558254791,\n",
       " 0.0015903439390171114,\n",
       " 0.0015903439390171114,\n",
       " 0.0015809286416469505,\n",
       " 0.0015809286416469505,\n",
       " 0.0015282251165394485,\n",
       " 0.0015282251165394485,\n",
       " 0.001093433876696988,\n",
       " 0.001093433876696988,\n",
       " 0.0010789724739226,\n",
       " 0.0010789724739226,\n",
       " 0.0010657480669755389,\n",
       " 0.0010657480669755389,\n",
       " 0.001017516377468696,\n",
       " 0.001017516377468696,\n",
       " 0.000682421512562405,\n",
       " 0.000682421512562405,\n",
       " 0.00027668810928164534,\n",
       " 0.00027668810928164534]"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_corrs_gbfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9846192697922241,\n",
       " 0.9846192697922241,\n",
       " 0.9845410459996977,\n",
       " 0.9845410459996977,\n",
       " 0.9769020337954466,\n",
       " 0.9769020337954466,\n",
       " 0.9687895210816628,\n",
       " 0.9687895210816628,\n",
       " 0.9620409951220529,\n",
       " 0.9620409951220529,\n",
       " 0.9492998902330713,\n",
       " 0.9492998902330713,\n",
       " 0.8457863250560569,\n",
       " 0.8457863250560569,\n",
       " 0.8422972828678092,\n",
       " 0.8422972828678092,\n",
       " 0.8412954054821885,\n",
       " 0.8412954054821885,\n",
       " 0.809745216725141,\n",
       " 0.809745216725141,\n",
       " 0.7831397784376068,\n",
       " 0.7831397784376068,\n",
       " 0.7428725596119059,\n",
       " 0.7428725596119059,\n",
       " 0.7275164254595075,\n",
       " 0.7275164254595075,\n",
       " 0.7152472801761548,\n",
       " 0.7152472801761548,\n",
       " 0.6325720093735401,\n",
       " 0.6325720093735401,\n",
       " 0.6322416559144532,\n",
       " 0.6322416559144532,\n",
       " 0.6239152178779184,\n",
       " 0.6239152178779184,\n",
       " 0.6217452460388495,\n",
       " 0.6217452460388495,\n",
       " 0.6156922771900486,\n",
       " 0.6156922771900486,\n",
       " 0.6103961738136551,\n",
       " 0.6103961738136551,\n",
       " 0.6067205279194183,\n",
       " 0.6067205279194183,\n",
       " 0.6054255793127183,\n",
       " 0.6054255793127183,\n",
       " 0.6027762441143815,\n",
       " 0.6027762441143815,\n",
       " 0.6019609535905257,\n",
       " 0.6019609535905257,\n",
       " 0.58444412147378,\n",
       " 0.58444412147378,\n",
       " 0.5658149791481695,\n",
       " 0.5658149791481695,\n",
       " 0.5438169506729135,\n",
       " 0.5438169506729135,\n",
       " 0.5319496330892646,\n",
       " 0.5319496330892646,\n",
       " 0.5308620151262189,\n",
       " 0.5308620151262189,\n",
       " 0.51873543310554,\n",
       " 0.51873543310554,\n",
       " 0.5175225728319743,\n",
       " 0.5175225728319743,\n",
       " 0.5118699166287197,\n",
       " 0.5118699166287197,\n",
       " 0.4985750823757591,\n",
       " 0.4985750823757591,\n",
       " 0.4637431301681787,\n",
       " 0.4637431301681787,\n",
       " 0.4540718830355042,\n",
       " 0.4540718830355042,\n",
       " 0.4489958866592013,\n",
       " 0.4489958866592013,\n",
       " 0.4441880337434147,\n",
       " 0.4441880337434147,\n",
       " 0.4434406174846865,\n",
       " 0.4434406174846865,\n",
       " 0.4403093357289544,\n",
       " 0.4403093357289544,\n",
       " 0.4205484029647536,\n",
       " 0.4205484029647536,\n",
       " 0.4196197695538406,\n",
       " 0.4196197695538406,\n",
       " 0.4049691489870067,\n",
       " 0.4049691489870067,\n",
       " 0.4041625053377,\n",
       " 0.4041625053377,\n",
       " 0.4032563437031885,\n",
       " 0.4032563437031885,\n",
       " 0.40273651182284453,\n",
       " 0.40273651182284453,\n",
       " 0.39956050616255534,\n",
       " 0.39956050616255534,\n",
       " 0.3986034633023924,\n",
       " 0.3986034633023924,\n",
       " 0.39525824308484125,\n",
       " 0.39525824308484125,\n",
       " 0.38755453681694735,\n",
       " 0.38755453681694735,\n",
       " 0.386268217346043,\n",
       " 0.386268217346043,\n",
       " 0.3853076206687164,\n",
       " 0.3853076206687164,\n",
       " 0.38374242285963706,\n",
       " 0.38374242285963706,\n",
       " 0.37783134634671556,\n",
       " 0.37783134634671556,\n",
       " 0.37639656951813827,\n",
       " 0.37639656951813827,\n",
       " 0.37619237913196923,\n",
       " 0.37619237913196923,\n",
       " 0.3713196765979985,\n",
       " 0.3713196765979985,\n",
       " 0.3643617212067378,\n",
       " 0.3643617212067378,\n",
       " 0.3553709279208339,\n",
       " 0.3553709279208339,\n",
       " 0.3272417267139362,\n",
       " 0.3272417267139362,\n",
       " 0.32228491578003016,\n",
       " 0.32228491578003016,\n",
       " 0.30236078460453725,\n",
       " 0.30236078460453725,\n",
       " 0.30005549227768663,\n",
       " 0.30005549227768663,\n",
       " 0.2771618626189518,\n",
       " 0.2771618626189518,\n",
       " 0.2764172479217508,\n",
       " 0.2764172479217508,\n",
       " 0.2656676729096739,\n",
       " 0.2656676729096739,\n",
       " 0.2630891988310385,\n",
       " 0.2630891988310385,\n",
       " 0.24264612865216814,\n",
       " 0.24264612865216814,\n",
       " 0.24196756949139872,\n",
       " 0.24196756949139872,\n",
       " 0.24071927190953682,\n",
       " 0.24071927190953682,\n",
       " 0.21683395709044836,\n",
       " 0.21683395709044836,\n",
       " 0.21655740433122872,\n",
       " 0.21655740433122872,\n",
       " 0.21424021088784154,\n",
       " 0.21424021088784154,\n",
       " 0.213160807108888,\n",
       " 0.213160807108888,\n",
       " 0.21272256213858273,\n",
       " 0.21272256213858273,\n",
       " 0.2095270096608015,\n",
       " 0.2095270096608015,\n",
       " 0.20393034012306654,\n",
       " 0.20393034012306654,\n",
       " 0.20305532647215413,\n",
       " 0.20305532647215413,\n",
       " 0.19435198117174876,\n",
       " 0.19435198117174876,\n",
       " 0.19158540666707236,\n",
       " 0.19158540666707236,\n",
       " 0.1893161473725389,\n",
       " 0.1893161473725389,\n",
       " 0.18451502364871744,\n",
       " 0.18451502364871744,\n",
       " 0.17795938316743262,\n",
       " 0.17795938316743262,\n",
       " 0.16670631439079808,\n",
       " 0.16670631439079808,\n",
       " 0.14366137564177334,\n",
       " 0.14366137564177334,\n",
       " 0.14270698368403095,\n",
       " 0.14270698368403095,\n",
       " 0.13719889312769507,\n",
       " 0.13719889312769507,\n",
       " 0.12731686518471594,\n",
       " 0.12731686518471594,\n",
       " 0.12600583912952812,\n",
       " 0.12600583912952812,\n",
       " 0.12582653312305891,\n",
       " 0.12582653312305891,\n",
       " 0.12090255089152589,\n",
       " 0.12090255089152589,\n",
       " 0.12027047620244592,\n",
       " 0.12027047620244592,\n",
       " 0.11992420971443658,\n",
       " 0.11992420971443658,\n",
       " 0.11748985962811025,\n",
       " 0.11748985962811025,\n",
       " 0.11717296189752517,\n",
       " 0.11717296189752517,\n",
       " 0.11601303034941703,\n",
       " 0.11601303034941703,\n",
       " 0.11347127188880565,\n",
       " 0.11347127188880565,\n",
       " 0.11011106758715629,\n",
       " 0.11011106758715629,\n",
       " 0.1070016828901424,\n",
       " 0.1070016828901424,\n",
       " 0.09594239250489538,\n",
       " 0.09594239250489538,\n",
       " 0.09360101301730271,\n",
       " 0.09360101301730271,\n",
       " 0.09110202217042603,\n",
       " 0.09110202217042603,\n",
       " 0.08791176864337577,\n",
       " 0.08791176864337577,\n",
       " 0.08359162406726604,\n",
       " 0.08359162406726604,\n",
       " 0.08329724768526812,\n",
       " 0.08329724768526812,\n",
       " 0.0825974186671221,\n",
       " 0.0825974186671221,\n",
       " 0.08103211447372557,\n",
       " 0.08103211447372557,\n",
       " 0.0808575762802882,\n",
       " 0.0808575762802882,\n",
       " 0.07926604475461127,\n",
       " 0.07926604475461127,\n",
       " 0.07785057103854848,\n",
       " 0.07785057103854848,\n",
       " 0.07740276283762883,\n",
       " 0.07740276283762883,\n",
       " 0.07475091459993487,\n",
       " 0.07475091459993487,\n",
       " 0.07437490725190148,\n",
       " 0.07437490725190148,\n",
       " 0.07426577718023823,\n",
       " 0.07426577718023823,\n",
       " 0.07416089417639209,\n",
       " 0.07416089417639209,\n",
       " 0.07133186557288314,\n",
       " 0.07133186557288314,\n",
       " 0.07120911215651309,\n",
       " 0.07120911215651309,\n",
       " 0.06850691551081722,\n",
       " 0.06850691551081722,\n",
       " 0.06752463496910534,\n",
       " 0.06752463496910534,\n",
       " 0.06698158763167984,\n",
       " 0.06698158763167984,\n",
       " 0.06651669741102204,\n",
       " 0.06651669741102204,\n",
       " 0.0653731917028739,\n",
       " 0.0653731917028739,\n",
       " 0.062278956872389726,\n",
       " 0.062278956872389726,\n",
       " 0.0612823017134084,\n",
       " 0.0612823017134084,\n",
       " 0.059938653537266275,\n",
       " 0.059938653537266275,\n",
       " 0.05903349872387526,\n",
       " 0.05903349872387526,\n",
       " 0.057679652141759304,\n",
       " 0.057679652141759304,\n",
       " 0.05738256447025297,\n",
       " 0.05738256447025297,\n",
       " 0.05638884791636202,\n",
       " 0.05638884791636202,\n",
       " 0.05499853320694488,\n",
       " 0.05499853320694488,\n",
       " 0.0529798661715275,\n",
       " 0.0529798661715275,\n",
       " 0.049827406039493476,\n",
       " 0.049827406039493476,\n",
       " 0.04903622889512391,\n",
       " 0.04903622889512391,\n",
       " 0.04894284038483607,\n",
       " 0.04894284038483607,\n",
       " 0.048089441301837815,\n",
       " 0.048089441301837815,\n",
       " 0.04752691379292211,\n",
       " 0.04752691379292211,\n",
       " 0.04677686545226045,\n",
       " 0.04677686545226045,\n",
       " 0.04675203428278105,\n",
       " 0.04675203428278105,\n",
       " 0.04574053798615528,\n",
       " 0.04574053798615528,\n",
       " 0.045076613485705366,\n",
       " 0.045076613485705366,\n",
       " 0.04461642271843702,\n",
       " 0.04461642271843702,\n",
       " 0.043716689210409256,\n",
       " 0.043716689210409256,\n",
       " 0.04245131209140773,\n",
       " 0.04245131209140773,\n",
       " 0.04147727291000091,\n",
       " 0.04147727291000091,\n",
       " 0.041043519925370135,\n",
       " 0.041043519925370135,\n",
       " 0.040336914117665934,\n",
       " 0.040336914117665934,\n",
       " 0.04005049538486507,\n",
       " 0.04005049538486507,\n",
       " 0.03983236118018429,\n",
       " 0.03983236118018429,\n",
       " 0.039807607692456615,\n",
       " 0.039807607692456615,\n",
       " 0.039707052964804854,\n",
       " 0.039707052964804854,\n",
       " 0.03890443947639142,\n",
       " 0.03890443947639142,\n",
       " 0.035205862247581064,\n",
       " 0.035205862247581064,\n",
       " 0.03272226329954329,\n",
       " 0.03272226329954329,\n",
       " 0.03148337638603868,\n",
       " 0.03148337638603868,\n",
       " 0.0300909120394068,\n",
       " 0.0300909120394068,\n",
       " 0.029806278132756353,\n",
       " 0.029806278132756353,\n",
       " 0.027967442443606272,\n",
       " 0.027967442443606272,\n",
       " 0.02624850290755252,\n",
       " 0.02624850290755252,\n",
       " 0.025599662032296314,\n",
       " 0.025599662032296314,\n",
       " 0.021662591670703623,\n",
       " 0.021662591670703623,\n",
       " 0.02056823247389945,\n",
       " 0.02056823247389945,\n",
       " 0.019233896495271414,\n",
       " 0.019233896495271414,\n",
       " 0.01884799569624838,\n",
       " 0.01884799569624838,\n",
       " 0.018249618632667632,\n",
       " 0.018249618632667632,\n",
       " 0.018036737880755438,\n",
       " 0.018036737880755438,\n",
       " 0.017973346733017113,\n",
       " 0.017973346733017113,\n",
       " 0.017051171378049016,\n",
       " 0.017051171378049016,\n",
       " 0.014416040317586233,\n",
       " 0.014416040317586233,\n",
       " 0.011984653528220863,\n",
       " 0.011984653528220863,\n",
       " 0.010808173741027376,\n",
       " 0.010808173741027376,\n",
       " 0.010213889647985966,\n",
       " 0.010213889647985966,\n",
       " 0.009552386473888154,\n",
       " 0.009552386473888154,\n",
       " 0.009046479300411175,\n",
       " 0.009046479300411175,\n",
       " 0.007899399912993215,\n",
       " 0.007899399912993215,\n",
       " 0.006743226031889633,\n",
       " 0.006743226031889633,\n",
       " 0.006629921311034454,\n",
       " 0.006629921311034454,\n",
       " 0.005951065969895424,\n",
       " 0.005951065969895424,\n",
       " 0.005400726999158937,\n",
       " 0.005400726999158937,\n",
       " 0.0051259260721103345,\n",
       " 0.0051259260721103345,\n",
       " 0.004687252072757656,\n",
       " 0.004687252072757656,\n",
       " 0.004560193548814654,\n",
       " 0.004560193548814654,\n",
       " 0.0038827512287826966,\n",
       " 0.0038827512287826966,\n",
       " 0.0037442253998533352,\n",
       " 0.0037442253998533352,\n",
       " 0.0022318916861110293,\n",
       " 0.0022318916861110293,\n",
       " 0.0019592038151034124,\n",
       " 0.0019592038151034124,\n",
       " 0.001388932626787404,\n",
       " 0.001388932626787404,\n",
       " 0.0013448459774759909,\n",
       " 0.0013448459774759909,\n",
       " 0.0010819097641909265,\n",
       " 0.0010819097641909265,\n",
       " 0.0009706867585772862,\n",
       " 0.0009706867585772862,\n",
       " 0.0006287372198643957,\n",
       " 0.0006287372198643957,\n",
       " 0.0005392478313370848,\n",
       " 0.0005392478313370848]"
      ]
     },
     "execution_count": 225,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_corrs_spearman_gbfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(abs_corrs_gbdt, color='g',\n",
    "         lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "plt.plot(abs_corrs_gbfs, color='darkorange',\n",
    "         lw=lw, label='GBFS',marker=\"o\")\n",
    "#plt.ylim([0.6,1])\n",
    "#plt.xlim([0,200])\n",
    "plt.xlabel('id')\n",
    "plt.ylabel('absolute correlations')\n",
    "plt.title('sorted absolute pearson correlations')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(abs_corrs_spearman_gbdt, color='g',\n",
    "         lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "plt.plot(abs_corrs_spearman_gbfs, color='darkorange',\n",
    "         lw=lw, label='GBFS',marker=\"o\")\n",
    "plt.ylim([0.6,1])\n",
    "plt.xlim([0,29])\n",
    "plt.xlabel('id')\n",
    "plt.ylabel('absolute correlations')\n",
    "plt.title('sorted absolute spearman correlations')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc3eff3b2e8>"
      ]
     },
     "execution_count": 234,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(GBDTBTt_corr.iloc[:20,:20].abs(),cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc52f2cfba8>"
      ]
     },
     "execution_count": 236,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(GBDTBTt_corr_spearman.iloc[:20,:20].abs(),cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc5504e47f0>"
      ]
     },
     "execution_count": 237,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(GBFS_corr.iloc[:20,:20].abs(),cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x7fc3efea8b00>"
      ]
     },
     "execution_count": 238,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 288x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.matshow(GBFS_corr_spearman.iloc[:19,:19].abs(),cmap=plt.cm.Blues)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
