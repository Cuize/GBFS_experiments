{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [],
   "source": [
    "from os import listdir\n",
    "from os.path import isfile, join\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from sklearn.metrics import roc_auc_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ranking_precision_score(y_true, y_score, k=10):\n",
    "    \"\"\"Precision at rank k\n",
    "    Parameters\n",
    "    ----------\n",
    "    y_true : array-like, shape = [n_samples]\n",
    "        Ground truth (true relevance labels).\n",
    "    y_score : array-like, shape = [n_samples]\n",
    "        Predicted scores.\n",
    "    k : int\n",
    "        Rank.\n",
    "    Returns\n",
    "    -------\n",
    "    precision @k : float\n",
    "    \"\"\"\n",
    "    unique_y = np.unique(y_true)\n",
    "\n",
    "    if len(unique_y) == 2:\n",
    "        pos_label = unique_y[1]\n",
    "        n_pos = np.sum(y_true == pos_label)\n",
    "\n",
    "        order = np.argsort(y_score)[::-1]\n",
    "        y_true = np.take(y_true, order[:k])\n",
    "        n_relevant = np.sum(y_true == pos_label)\n",
    "\n",
    "        # Divide by min(n_pos, k) such that the best achievable score is always 1.0.\n",
    "        return float(n_relevant) / min(n_pos, k)\n",
    "    else:\n",
    "        return -1\n",
    "def rank_precision(data_frame,k=4): # passed to groupby object \n",
    "    y_true=list(data_frame[1])\n",
    "    y_score=list(data_frame[2])\n",
    "    return ranking_precision_score(y_true, y_score, k=k)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Model:\n",
    "    def __init__(self,name=\"GBDT\",alpha=0,penalty=0,topk=-1,attrN=-1,preds=None,rmse=-1):\n",
    "        self.name=name  # name can be GBDT or GBDTBT (GBDT with top ranking feature from BT)\n",
    "        self.pen=penalty\n",
    "        self.topk=topk\n",
    "        self.preds=preds\n",
    "        self.attrN=attrN\n",
    "        self.alpha=alpha\n",
    "        self.rmse=rmse\n",
    "        \n",
    "    def get_AUC(self):\n",
    "        return roc_auc_score(trueY,self.preds) if self.preds is not None else None\n",
    "    \n",
    "    #add some other metrics later\n",
    "    \n",
    "    def get_ranking_precision(self,k=2): # ranking_precision_score averaged over queries\n",
    "        combined=pd.concat([kw,trueY,self.preds],axis=1,ignore_index=True)\n",
    "        grouped=combined.groupby(combined[0])\n",
    "        agged=grouped.apply(rank_precision,k=k)\n",
    "        agged=[num for num in agged if num>=0]\n",
    "        return sum(agged)/(len(agged)) if len(agged)>0 else 0\n",
    "        \n",
    "        \n",
    "        \n",
    "        \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "###### result files paths\n",
    "\n",
    "# result_path='result/us/'\n",
    "# attr_total=174\n",
    "\n",
    "# result_path='result/us_adaptive'\n",
    "# attr_total=174\n",
    "\n",
    "# result_path='result/gold_in_qa_split_new/'\n",
    "# attr_total=96\n",
    "\n",
    "result_path='result/gold_in_qa_split_adaptive/'\n",
    "attr_total=96\n",
    "\n",
    "\n",
    "# result_path='result/madelon/'\n",
    "# attr_total=500\n",
    "\n",
    "# result_path='result/madelon_adaptive/'\n",
    "# attr_total=500\n",
    "\n",
    "\n",
    "\n",
    "# result_path='synthetic/result_syn1_test/'\n",
    "# aux_path='synthetic/aux_result_syn1_test/'\n",
    "# attr_total=100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess\n",
    "\n",
    "filenames_result=listdir(result_path)\n",
    "trueY=pd.read_csv(result_path+\"trueY.txt\",header=None)[0]\n",
    "try:\n",
    "    kw=pd.read_csv(result_path+\"keyword.txt\",header=None)[0]\n",
    "except:\n",
    "    print(\"do not have groups\")\n",
    "try:\n",
    "    number_unused=len(pd.read_csv(result_path+\"preprocess_unused.txt\",header=None))\n",
    "except:\n",
    "    number_unused=0\n",
    "attr_init_number=attr_total-number_unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "67"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "attr_init_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['boosting_rms_GBFS_mu0.9_alpha0.txt',\n",
       " 'log_GBFS_mu0.08_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.8_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.55_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.01_alpha0.txt',\n",
       " 'log_GBFS_mu0.01_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.02_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.5_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.25_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.6_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.8_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.3_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.05_alpha0.txt',\n",
       " 'log_GBFS_mu0.01_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.5_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.6_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.25_alpha0.1.txt',\n",
       " 'GBFS_mu0.12_preds_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.5_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.2_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.7_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.4_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.01_alpha0.02.txt',\n",
       " 'GBFS_mu0.35_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.45_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.4_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.02_alpha0.txt',\n",
       " 'GBFS_mu0.08_preds_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.08_alpha0.txt',\n",
       " 'log_GBFS_mu0.08_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.9_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.01_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.8_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.01_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.1_alpha0.txt',\n",
       " 'log_GBFS_mu0.12_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.18_alpha0.01.txt',\n",
       " 'GBFS_mu0.7_preds_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.35_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.1_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.95_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.18_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.9_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.55_alpha0.txt',\n",
       " 'log_GBFS_mu0.3_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.1_alpha0.1.txt',\n",
       " 'GBFS_mu0.08_preds_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.1_alpha0.02.txt',\n",
       " 'GBFS_mu0.6_preds_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.5_alpha0.1.txt',\n",
       " 'GBFS_mu0.2_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.9_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.18_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.2_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.18_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.55_alpha0.001.txt',\n",
       " 'GBFS_mu0.15_preds_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.35_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.35_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.95_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.9_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.5_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.55_alpha0.001.txt',\n",
       " 'GBFS_mu0.02_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.35_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.12_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.05_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.18_alpha0.001.txt',\n",
       " 'GBFS_mu0.45_preds_alpha0.02.txt',\n",
       " 'GBFS_mu0.55_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.18_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.3_alpha0.txt',\n",
       " 'log_GBFS_mu0.02_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.2_alpha0.02.txt',\n",
       " 'GBFS_mu0.9_preds_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.8_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.15_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.35_alpha0.1.txt',\n",
       " 'GBFS_mu0.4_preds_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.55_alpha0.01.txt',\n",
       " 'GBFS_mu0.45_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.08_alpha0.txt',\n",
       " 'log_GBFS_mu0.9_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.2_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.01_alpha0.1.txt',\n",
       " 'GBFS_mu0.8_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.5_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.25_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.05_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.18_alpha0.txt',\n",
       " 'GBFS_mu0.4_preds_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.15_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.18_alpha0.001.txt',\n",
       " 'GBFS_mu0.95_preds_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.2_alpha0.001.txt',\n",
       " 'GBFS_mu0.01_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.25_preds_alpha0.01.txt',\n",
       " 'GBFS_mu0.12_preds_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.1_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.02_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.25_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.02_alpha0.01.txt',\n",
       " 'trueY.txt',\n",
       " 'GBFS_mu0.8_preds_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.5_alpha0.001.txt',\n",
       " 'GBFS_mu0.18_preds_alpha0.02.txt',\n",
       " 'preprocess_unused.txt',\n",
       " 'feature_scores_GBFS_mu0.55_alpha0.01.txt',\n",
       " 'GBFS_mu0.02_preds_alpha0.02.txt',\n",
       " 'GBFS_mu0.18_preds_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.8_alpha0.1.txt',\n",
       " 'GBFS_mu0.35_preds_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.3_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.2_alpha0.txt',\n",
       " 'GBFS_mu0.2_preds_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.05_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.8_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.05_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.9_alpha0.001.txt',\n",
       " 'GBFS_mu0.5_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.18_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.01_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.02_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.1_alpha0.02.txt',\n",
       " 'GBFS_mu0.18_preds_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.12_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.6_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.4_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.3_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.4_alpha0.02.txt',\n",
       " 'GBFS_mu0.25_preds_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.25_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.3_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.15_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.1_alpha0.txt',\n",
       " 'GBFS_mu0.6_preds_alpha0.02.txt',\n",
       " 'GBFS_mu0.12_preds_alpha0.1.txt',\n",
       " 'GBFS_mu0.55_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.18_alpha0.1.txt',\n",
       " 'GBFS_mu0.05_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.05_alpha0.02.txt',\n",
       " 'GBFS_mu0.18_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.7_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.08_alpha0.02.txt',\n",
       " 'GBFS_mu0.18_preds_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.95_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.2_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.18_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.12_alpha0.txt',\n",
       " 'GBFS_mu0.7_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.55_alpha0.001.txt',\n",
       " 'GBFS_mu0.35_preds_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.6_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.12_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.6_alpha0.txt',\n",
       " 'GBFS_mu0.12_preds_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.35_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.2_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.18_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.05_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.12_alpha0.001.txt',\n",
       " 'GBFS_mu0.15_preds_alpha0.txt',\n",
       " 'log_GBFS_mu0.25_alpha0.txt',\n",
       " 'log_GBFS_mu0.7_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.45_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.4_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.55_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.15_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.12_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.8_alpha0.01.txt',\n",
       " 'GBFS_mu0.25_preds_alpha0.txt',\n",
       " 'GBFS_mu0.6_preds_alpha0.01.txt',\n",
       " 'GBFS_mu0.35_preds_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.2_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.15_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.8_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.45_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.12_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.3_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.45_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.01_alpha0.txt',\n",
       " 'GBFS_mu0.6_preds_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.45_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.6_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.02_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.55_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.4_alpha0.02.txt',\n",
       " 'GBFS_mu0.5_preds_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.01_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.15_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.4_alpha0.01.txt',\n",
       " 'GBFS_mu0.8_preds_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.55_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.7_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.8_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.5_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.05_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.01_alpha0.001.txt',\n",
       " 'GBFS_mu0.02_preds_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.25_alpha0.02.txt',\n",
       " 'GBFS_mu0.55_preds_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.8_alpha0.02.txt',\n",
       " 'GBFS_mu0.1_preds_alpha0.02.txt',\n",
       " 'GBFS_mu0.4_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.12_alpha0.02.txt',\n",
       " 'GBFS_mu0.5_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.25_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.1_alpha0.1.txt',\n",
       " 'GBFS_mu0.01_preds_alpha0.02.txt',\n",
       " 'GBFS_mu0.1_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.95_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.12_alpha0.txt',\n",
       " 'log_GBFS_mu0.9_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.5_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.05_alpha0.txt',\n",
       " 'GBFS_mu0.95_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.95_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.3_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.01_alpha0.01.txt',\n",
       " 'GBFS_mu0.8_preds_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.6_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.18_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.02_alpha0.01.txt',\n",
       " 'GBFS_mu0.05_preds_alpha0.txt',\n",
       " 'log_GBFS_mu0.6_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.08_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.08_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.95_alpha0.1.txt',\n",
       " 'GBFS_mu0.3_preds_alpha0.txt',\n",
       " 'GBFS_mu0.3_preds_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.3_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.02_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.35_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.9_alpha0.1.txt',\n",
       " 'GBFS_mu0.4_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.95_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.55_alpha0.02.txt',\n",
       " 'GBFS_mu0.45_preds_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.8_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.5_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.02_alpha0.01.txt',\n",
       " 'GBFS_mu0.01_preds_alpha0.txt',\n",
       " 'gold_in_qa_split_test.dta',\n",
       " 'feature_scores_GBFS_mu0.4_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.7_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.2_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.7_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.1_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.95_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.45_alpha0.02.txt',\n",
       " 'gold_in_qa_split_train.attr',\n",
       " 'GBFS_mu0.15_preds_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.4_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.05_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.15_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.02_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.05_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.45_alpha0.txt',\n",
       " 'GBFS_mu0.9_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.08_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.15_preds_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.7_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.3_alpha0.01.txt',\n",
       " 'GBFS_mu0.2_preds_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.45_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.01_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.6_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.7_alpha0.txt',\n",
       " 'GBFS_mu0.3_preds_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.55_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.15_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.2_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.95_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.25_alpha0.001.txt',\n",
       " 'GBFS_mu0.7_preds_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.55_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.95_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.35_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.8_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.45_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.9_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.5_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.6_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.3_alpha0.001.txt',\n",
       " 'GBFS_mu0.9_preds_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.2_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.1_alpha0.01.txt',\n",
       " 'GBFS_mu0.05_preds_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.3_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.02_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.45_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.35_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.08_alpha0.1.txt',\n",
       " 'GBFS_mu0.1_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.7_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.9_alpha0.02.txt',\n",
       " 'GBFS_mu0.05_preds_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.02_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.6_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.6_alpha0.01.txt',\n",
       " 'GBFS_mu0.5_preds_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.7_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.12_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.2_alpha0.01.txt',\n",
       " 'GBFS_mu0.12_preds_alpha0.txt',\n",
       " 'log_GBFS_mu0.45_alpha0.txt',\n",
       " 'log_GBFS_mu0.8_alpha0.001.txt',\n",
       " 'keyword.txt',\n",
       " 'boosting_rms_GBFS_mu0.55_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.08_alpha0.01.txt',\n",
       " 'GBFS_mu0.55_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.01_preds_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.1_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.08_alpha0.001.txt',\n",
       " 'GBFS_mu0.95_preds_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.1_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.35_alpha0.txt',\n",
       " 'GBFS_mu0.25_preds_alpha0.1.txt',\n",
       " 'GBFS_mu0.9_preds_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.5_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.35_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.45_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.7_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.08_alpha0.001.txt',\n",
       " 'GBFS_mu0.02_preds_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.25_alpha0.txt',\n",
       " 'log_GBFS_mu0.15_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.25_alpha0.02.txt',\n",
       " 'GBFS_mu0.25_preds_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.9_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.1_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.2_alpha0.txt',\n",
       " 'log_GBFS_mu0.4_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.12_alpha0.001.txt',\n",
       " 'GBFS_mu0.45_preds_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.7_alpha0.001.txt',\n",
       " 'GBFS_mu0.08_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.02_alpha0.txt',\n",
       " 'GBFS_mu0.15_preds_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.2_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.01_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.1_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.35_alpha0.1.txt',\n",
       " 'GBFS_mu0.01_preds_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.9_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.1_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.6_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.7_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.4_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.05_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.7_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.95_alpha0.01.txt',\n",
       " 'GBFS_mu0.35_preds_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.25_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.6_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.15_alpha0.01.txt',\n",
       " 'GBFS_mu0.6_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.55_preds_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.35_alpha0.01.txt',\n",
       " 'GBFS_mu0.3_preds_alpha0.1.txt',\n",
       " 'boosting_rms_GBFS_mu0.08_alpha0.02.txt',\n",
       " 'GBFS_mu0.8_preds_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.35_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.05_alpha0.001.txt',\n",
       " 'GBFS_mu0.1_preds_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.45_alpha0.02.txt',\n",
       " 'GBFS_mu0.2_preds_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.08_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.35_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.4_alpha0.txt',\n",
       " 'feature_scores_GBFS_mu0.45_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.9_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.05_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.5_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.3_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.12_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.25_alpha0.01.txt',\n",
       " 'GBFS_mu0.02_preds_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.4_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.08_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.45_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.05_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.8_alpha0.02.txt',\n",
       " 'boosting_rms_GBFS_mu0.3_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.95_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.5_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.15_alpha0.1.txt',\n",
       " 'GBFS_mu0.95_preds_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.15_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.4_alpha0.txt',\n",
       " 'GBFS_mu0.7_preds_alpha0.001.txt',\n",
       " 'GBFS_mu0.2_preds_alpha0.1.txt',\n",
       " 'GBFS_mu0.05_preds_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.25_alpha0.001.txt',\n",
       " 'feature_scores_GBFS_mu0.15_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.02_alpha0.txt',\n",
       " 'GBFS_mu0.9_preds_alpha0.txt',\n",
       " 'log_GBFS_mu0.15_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.7_alpha0.01.txt',\n",
       " 'GBFS_mu0.45_preds_alpha0.1.txt',\n",
       " 'feature_scores_GBFS_mu0.95_alpha0.001.txt',\n",
       " 'boosting_rms_GBFS_mu0.8_alpha0.001.txt',\n",
       " 'log_GBFS_mu0.15_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.01_alpha0.txt',\n",
       " 'GBFS_mu0.3_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.55_alpha0.1.txt',\n",
       " 'log_GBFS_mu0.5_alpha0.txt',\n",
       " 'GBFS_mu0.1_preds_alpha0.01.txt',\n",
       " 'boosting_rms_GBFS_mu0.12_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.6_alpha0.01.txt',\n",
       " 'GBFS_mu0.08_preds_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.18_alpha0.txt',\n",
       " 'GBFS_mu0.5_preds_alpha0.txt',\n",
       " 'log_GBFS_mu0.9_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.08_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.4_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.3_alpha0.02.txt',\n",
       " 'feature_scores_GBFS_mu0.18_alpha0.txt',\n",
       " 'gold_in_qa_split_train.dta',\n",
       " 'log_GBFS_mu0.25_alpha0.01.txt',\n",
       " 'GBFS_mu0.4_preds_alpha0.01.txt',\n",
       " 'feature_scores_GBFS_mu0.95_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.12_alpha0.01.txt',\n",
       " 'log_GBFS_mu0.95_alpha0.txt',\n",
       " 'boosting_rms_GBFS_mu0.95_alpha0.02.txt',\n",
       " 'log_GBFS_mu0.7_alpha0.1.txt']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "filenames_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store result for adaptive GBFS\n",
    "GBFS_adaptive_dict=collections.defaultdict(dict) # store preds,attrN for different 0<mu<1 and alpha\n",
    "for filename in filenames_result:\n",
    "    last_dot=filename.rfind(\".\")\n",
    "    fname,fext=filename[:last_dot],filename[last_dot+1:]\n",
    "    if fext==\"txt\" and \"_alpha\" in fname:\n",
    "        alpha=float(fname[fname.index(\"_alpha\")+6:])\n",
    "        if \"_preds\" in fname:\n",
    "            preds=pd.read_csv(result_path+filename,header=None)[0]\n",
    "            idx=fname.index(\"_mu\")\n",
    "            mu=float(fname[idx+3:fname.index(\"_preds\")])\n",
    "            GBFS_adaptive_dict[mu,alpha][\"preds\"]=preds\n",
    "        elif \"feature_scores_\" in fname:\n",
    "            tmp=pd.read_csv(result_path+filename,header=None)[0][0] # the first line of feature_score reports attrN\n",
    "            attrN=int(tmp.split()[-1])\n",
    "            idx=fname.index(\"_mu\")\n",
    "            mu=float(fname[idx+3:fname.index(\"_alpha\")])\n",
    "            GBFS_adaptive_dict[mu,alpha][\"attrN\"]=attrN\n",
    "        elif \"boosting_rms_\" in fname:\n",
    "            rmse=pd.read_csv(result_path+filename,header=None)[0].iloc[-1] # last line is the rmse\n",
    "            idx=fname.index(\"_mu\")\n",
    "            mu=float(fname[idx+3:fname.index(\"_alpha\")])\n",
    "            GBFS_adaptive_dict[mu,alpha][\"rmse\"]=rmse\n",
    "            \n",
    "            \n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "version problem\n",
      "version problem\n",
      "version problem\n",
      "version problem\n",
      "version problem\n"
     ]
    }
   ],
   "source": [
    "# store results when go through all files in result folder\n",
    "# index result like [(mu,alpha)]\n",
    "GBFS_dict=collections.defaultdict(dict) # store preds,attrN,rmse for different mu>0 and alpha\n",
    "GBDTt_dict=collections.defaultdict(dict) # indexed by alpha,topk\n",
    "GBDTBTt_dict=collections.defaultdict(dict) # store attrN and preds,rmse\n",
    "AttrN_GBDT={} # initial number of attr used for indexed by alpha\n",
    "AttrN_BT={} \n",
    "for filename in filenames_result:\n",
    "    last_dot=filename.rfind(\".\")\n",
    "    fname,fext=filename[:last_dot],filename[last_dot+1:]\n",
    "    if fext==\"txt\" and \"_alpha\" in fname:\n",
    "        alpha=float(fname[fname.index(\"_alpha\")+6:])\n",
    "        if \"_preds\" in fname:\n",
    "            preds=pd.read_csv(result_path+filename,header=None)[0]\n",
    "            if \"GBFSt\" in fname:\n",
    "                topk=int(fname[5:fname.index(\"_mu\")])\n",
    "                GBDTt_dict[alpha,topk][\"preds\"]=preds\n",
    "            elif \"GBDTBTt\" in fname:\n",
    "                topk=int(fname[7:fname.index(\"_preds\")])\n",
    "                GBDTBTt_dict[alpha,topk][\"preds\"]=preds\n",
    "            else:\n",
    "                idx=fname.index(\"_mu\")\n",
    "                mu=float(fname[idx+3:fname.index(\"_preds\")])\n",
    "                GBFS_dict[mu,alpha][\"preds\"]=preds\n",
    "        elif \"feature_scores_\" in fname:\n",
    "            tmp=pd.read_csv(result_path+filename,header=None)[0][0] # the first line of feature_score reports attrN\n",
    "            try:\n",
    "                attrN=int(tmp.split()[-1])\n",
    "            except:\n",
    "                print(\"version problem\")\n",
    "                attrN=attr_init_number\n",
    "            if \"_mu\" in fname:\n",
    "                idx=fname.index(\"_mu\")\n",
    "                mu=float(fname[idx+3:fname.index(\"_alpha\")])\n",
    "                GBFS_dict[mu,alpha][\"attrN\"]=attrN\n",
    "            elif \"_GBDT\" in fname:\n",
    "                AttrN_GBDT[alpha]=attrN\n",
    "                GBFS_dict[0,alpha][\"attrN\"]=attrN\n",
    "            else:\n",
    "                AttrN_BT[alpha]=attrN\n",
    "                \n",
    "        elif \"boosting_rms_\" in fname:\n",
    "            rmse=pd.read_csv(result_path+filename,header=None)[0].iloc[-1] # last line is the rmse\n",
    "            if \"GBFSt\" in fname:\n",
    "                topk=int(fname[18:fname.index(\"_mu\")])\n",
    "                GBDTt_dict[alpha,topk][\"rmse\"]=rmse\n",
    "            elif \"GBDTBTt\" in fname:\n",
    "                topk=int(fname[20:fname.index(\"_alpha\")])\n",
    "                GBDTBTt_dict[alpha,topk][\"rmse\"]=rmse\n",
    "            else:\n",
    "                idx=fname.index(\"_mu\")\n",
    "                mu=float(fname[idx+3:fname.index(\"_alpha\")])\n",
    "                GBFS_dict[mu,alpha][\"rmse\"]=rmse\n",
    "# get attrN's for GBDTt amd GBDTBTt which is min(topk,initial attrN in AttrN_GBDT and AttrN_BT for different alpha)\n",
    "for alpha,topk in GBDTt_dict:\n",
    "    GBDTt_dict[alpha,topk][\"attrN\"]=min(topk,AttrN_GBDT[alpha])\n",
    "for alpha,topk in GBDTBTt_dict:\n",
    "    GBDTBTt_dict[alpha,topk][\"attrN\"]=min(topk,AttrN_BT[alpha])\n",
    "\n",
    "                    \n",
    "                \n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put result together\n",
    "model_results=collections.defaultdict(list) # indexed by mu,alpha\n",
    "# GBFS model\n",
    "for mu,alpha in GBFS_dict:\n",
    "    try:\n",
    "        attrN=GBFS_dict[mu,alpha][\"attrN\"]\n",
    "        preds=GBFS_dict[mu,alpha][\"preds\"]\n",
    "        rmse=GBFS_dict[mu,alpha][\"rmse\"]\n",
    "        model_results[mu,alpha].append(Model(penalty=mu,alpha=alpha,topk=-1,attrN=attrN,preds=preds,rmse=rmse))\n",
    "    except:\n",
    "        print(\"not ready\")\n",
    "# GBDTt model\n",
    "for alpha,topk in GBDTt_dict:\n",
    "    preds=GBDTt_dict[alpha,topk][\"preds\"]\n",
    "    attrN=GBDTt_dict[alpha,topk][\"attrN\"]\n",
    "    rmse=GBDTt_dict[alpha,topk][\"rmse\"]\n",
    "    model_results[0,alpha].append(Model(alpha=alpha,topk=topk,attrN=attrN,preds=preds,rmse=rmse))\n",
    "    \n",
    "\n",
    "# GBDTBTt model\n",
    "for alpha,topk in GBDTBTt_dict:\n",
    "    preds=GBDTBTt_dict[alpha,topk][\"preds\"]\n",
    "    attrN=GBDTBTt_dict[alpha,topk][\"attrN\"]\n",
    "    rmse=GBDTBTt_dict[alpha,topk][\"rmse\"]\n",
    "    model_results[0,alpha].append(Model(name=\"GBDTBT\",alpha=alpha,topk=topk,attrN=attrN,preds=preds,rmse=rmse))\n",
    "    \n",
    "\n",
    "\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "#GBFS_adaptive model (0=<mu<=1)\n",
    "for mu,alpha in GBFS_adaptive_dict:\n",
    "    attrN=GBFS_adaptive_dict[mu,alpha][\"attrN\"]\n",
    "    preds=GBFS_adaptive_dict[mu,alpha][\"preds\"]\n",
    "    rmse=GBFS_adaptive_dict[mu,alpha][\"rmse\"]\n",
    "    model_results[mu,alpha].append(Model(penalty=mu,alpha=alpha,topk=-1,attrN=attrN,preds=preds,rmse=rmse))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## plots\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus=sorted(set(idx[0] for idx in GBFS_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=sorted(set(idx[1] for idx in GBFS_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot1 attrN v.s. mus for GBFS\n",
    "for alpha in alphas:\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x_axis=mus\n",
    "    y_axis=[GBFS_dict[mu,alpha][\"attrN\"] for mu in x_axis]\n",
    "    plt.plot(x_axis, y_axis, color='b',marker=\"o\",\n",
    "             lw=lw, label='GBFS')\n",
    "    #plt.xlim([0.0, max(x_axis)])\n",
    "    #plt.ylim([20, 100])\n",
    "    plt.xlabel('Penalty parameter mu')\n",
    "    plt.ylabel('Number of active features')\n",
    "    plt.title(f'Number of active features v.s. Penalty parameter mu with alpha={alpha}')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# alphas=[0,0.001,0.01,0.02,0.1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot1 attrN v.s. mus for GBFS_adaptive\n",
    "# for alpha in alphas:\n",
    "#     plt.figure()\n",
    "#     lw = 2\n",
    "#     x_axis=sorted(set(idx[0] for idx in GBFS_adaptive_dict.keys()))\n",
    "#     y_axis=[GBFS_adaptive_dict[mu,alpha][\"attrN\"] for mu in x_axis]\n",
    "#     plt.plot(x_axis, y_axis, color='b',marker=\"o\",\n",
    "#              lw=lw, label='GBFS')\n",
    "#     #plt.xlim([0.0, max(x_axis)])\n",
    "#     #plt.ylim([20, 100])\n",
    "#     plt.xlabel('Adaptive penalty parameter mu')\n",
    "#     plt.ylabel('Number of active features')\n",
    "#     plt.title(f'Number of active features v.s. Adaptive penalty parameter mu with alpha={alpha}')\n",
    "#     plt.legend(loc=\"upper right\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot2 AUC_ROC v.s. attrN (for best score with the given attrN for GBFS) given alpha # for adaptive mu\n",
    "\n",
    "# GBFS_adaptive=collections.defaultdict(int)\n",
    "# for mu,alpha in model_results:\n",
    "#     for model in model_results[mu,alpha]:\n",
    "#         if model.topk==-1 and model.pen>0: \n",
    "#             GBFS_adaptive[model.attrN,alpha]=max(GBFS_adaptive[model.attrN,alpha],model.get_AUC())\n",
    "# for alpha in alphas:        \n",
    "#     plt.figure()\n",
    "#     lw = 2\n",
    "#     x2_axis=sorted([idx[0] for idx in GBFS_adaptive.keys() if idx[1]==alpha])\n",
    "#     y2_axis=[GBFS_adaptive[x,alpha] for x in x2_axis]\n",
    "#     plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "#              lw=lw, label='GBFS',marker=\"o\")\n",
    "#     plt.xlabel('number of active features')\n",
    "#     plt.ylabel('AUC_ROC scores')\n",
    "#     plt.title(f'AUC_ROC scores v.s. number of active features with alpha={alpha}')\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot3 precision @2 v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "# GBFS_adaptive=collections.defaultdict(int)\n",
    "# for mu,alpha in model_results:\n",
    "#     for model in model_results[mu,alpha]:\n",
    "#         GBFS_adaptive[model.attrN,alpha]=max(GBFS_adaptive[model.attrN,alpha],model.get_ranking_precision())\n",
    "# for alpha in alphas:        \n",
    "#     plt.figure()\n",
    "#     lw = 2\n",
    "#     x2_axis=sorted([idx[0] for idx in GBFS_adaptive.keys() if idx[1]==alpha])\n",
    "#     y2_axis=[GBFS_adaptive[x,alpha] for x in x2_axis]\n",
    "#     plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "#              lw=lw, label='GBFS',marker=\"o\")\n",
    "#     plt.xlabel('number of active features')\n",
    "#     plt.ylabel('ranking_precision scores')\n",
    "#     plt.title(f'ranking_precision scores v.s. number of active features with alpha={alpha}')\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # plot 4 precision@k v.s. k for three models that with <=25 variables\n",
    "# ks=[2,3,4,5]\n",
    "# GBFS_adaptive=collections.defaultdict(int)\n",
    "# for mu,alpha in model_results:\n",
    "#     for model in model_results[mu,alpha]:\n",
    "#         for k in ks:\n",
    "#             GBFS_adaptive[alpha,k]=max(GBFS_adaptive[alpha,k],model.get_ranking_precision(k=k))\n",
    "# for alpha in alphas:        \n",
    "#     plt.figure()\n",
    "#     lw = 2\n",
    "#     y2_axis=[GBFS_adaptive[alpha,k] for k in ks]\n",
    "#     plt.plot(ks, y2_axis, color='darkorange',\n",
    "#              lw=lw, label='GBFS',marker=\"o\")\n",
    "#     plt.xlabel('k as in precision @k')\n",
    "#     plt.ylabel('ranking_precision scores')\n",
    "#     plt.title(f'ranking_precision scores @k v.s. k with alpha={alpha}')\n",
    "#     plt.legend(loc=\"lower right\")\n",
    "#     plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot2 AUC_ROC v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "GBDTBTt=collections.defaultdict(int)\n",
    "GBFS_adaptive=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                GBDTt[model.attrN,alpha]=max(GBDTt[model.attrN,alpha],model.get_AUC())\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                GBDTBTt[model.attrN,alpha]=max(GBDTBTt[model.attrN,alpha],model.get_AUC())\n",
    "            elif model.topk==-1 and model.pen>1: \n",
    "                GBFS[model.attrN,alpha]=max(GBFS[model.attrN,alpha],model.get_AUC())\n",
    "            elif model.topk==-1 and model.pen>0:\n",
    "                GBFS_adaptive[model.attrN,alpha]=max(GBFS_adaptive[model.attrN,alpha],model.get_AUC())\n",
    "                \n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x1_axis=sorted([idx[0] for idx in GBDTt.keys() if idx[1]==alpha])\n",
    "    y1_axis=[GBDTt[x,alpha] for x in x1_axis]\n",
    "    x2_axis=sorted([idx[0] for idx in GBFS.keys() if idx[1]==alpha])\n",
    "    y2_axis=[GBFS[x,alpha] for x in x2_axis]\n",
    "    x3_axis=sorted([idx[0] for idx in GBDTBTt.keys() if idx[1]==alpha])\n",
    "    y3_axis=[GBDTBTt[x,alpha] for x in x3_axis]\n",
    "    x4_axis=sorted([idx[0] for idx in GBFS_adaptive.keys() if idx[1]==alpha])\n",
    "    y4_axis=[GBFS_adaptive[x,alpha] for x in x4_axis]\n",
    "    \n",
    "    plt.plot(x1_axis, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.plot(x3_axis, y3_axis, color='b',\n",
    "             lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "    plt.plot(x4_axis, y4_axis, color='r',\n",
    "             lw=lw, label='GBFS_adapt',marker=\"o\")\n",
    "    \n",
    "    #plt.ylim([0.93, 0.95])\n",
    "    plt.xlabel('number of active features')\n",
    "    plt.ylabel('AUC_ROC scores')\n",
    "    plt.title(f'AUC_ROC scores v.s. number of active features with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot3 precision @2 v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "GBDTBTt=collections.defaultdict(int)\n",
    "GBFS_adaptive=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                GBDTt[model.attrN,alpha]=max(GBDTt[model.attrN,alpha],model.get_ranking_precision())\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                GBDTBTt[model.attrN,alpha]=max(GBDTBTt[model.attrN,alpha],model.get_ranking_precision())\n",
    "            elif model.topk==-1 and model.pen>1: \n",
    "                GBFS[model.attrN,alpha]=max(GBFS[model.attrN,alpha],model.get_ranking_precision())\n",
    "            elif model.topk==-1 and model.pen>0:\n",
    "                GBFS_adaptive[model.attrN,alpha]=max(GBFS_adaptive[model.attrN,alpha],model.get_ranking_precision())\n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x1_axis=sorted([idx[0] for idx in GBDTt.keys() if idx[1]==alpha])\n",
    "    y1_axis=[GBDTt[x,alpha] for x in x1_axis]\n",
    "    x2_axis=sorted([idx[0] for idx in GBFS.keys() if idx[1]==alpha])\n",
    "    y2_axis=[GBFS[x,alpha] for x in x2_axis]\n",
    "    x3_axis=sorted([idx[0] for idx in GBDTBTt.keys() if idx[1]==alpha])\n",
    "    y3_axis=[GBDTBTt[x,alpha] for x in x3_axis]\n",
    "    x4_axis=sorted([idx[0] for idx in GBFS_adaptive.keys() if idx[1]==alpha])\n",
    "    y4_axis=[GBFS_adaptive[x,alpha] for x in x4_axis]\n",
    "    plt.plot(x1_axis, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.plot(x3_axis, y3_axis, color='b',\n",
    "             lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "    plt.plot(x4_axis, y4_axis, color='r',\n",
    "             lw=lw, label='GBFS_adapt',marker=\"o\")\n",
    "    plt.xlabel('number of active features')\n",
    "    plt.ylabel('ranking_precision scores')\n",
    "    plt.title(f'ranking_precision scores v.s. number of active features with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot3 precision @4 v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "GBDTBTt=collections.defaultdict(int)\n",
    "GBFS_adaptive=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                GBDTt[model.attrN,alpha]=max(GBDTt[model.attrN,alpha],model.get_ranking_precision(k=4))\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                GBDTBTt[model.attrN,alpha]=max(GBDTBTt[model.attrN,alpha],model.get_ranking_precision(k=4))\n",
    "            elif model.topk==-1 and model.pen>1: \n",
    "                GBFS[model.attrN,alpha]=max(GBFS[model.attrN,alpha],model.get_ranking_precision(k=4))\n",
    "            elif model.topk==-1 and model.pen>0:\n",
    "                GBFS_adaptive[model.attrN,alpha]=max(GBFS_adaptive[model.attrN,alpha],model.get_ranking_precision(k=4))\n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x1_axis=sorted([idx[0] for idx in GBDTt.keys() if idx[1]==alpha])\n",
    "    y1_axis=[GBDTt[x,alpha] for x in x1_axis]\n",
    "    x2_axis=sorted([idx[0] for idx in GBFS.keys() if idx[1]==alpha])\n",
    "    y2_axis=[GBFS[x,alpha] for x in x2_axis]\n",
    "    x3_axis=sorted([idx[0] for idx in GBDTBTt.keys() if idx[1]==alpha])\n",
    "    y3_axis=[GBDTBTt[x,alpha] for x in x3_axis]\n",
    "    x4_axis=sorted([idx[0] for idx in GBFS_adaptive.keys() if idx[1]==alpha])\n",
    "    y4_axis=[GBFS_adaptive[x,alpha] for x in x4_axis]\n",
    "    plt.plot(x1_axis, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.plot(x3_axis, y3_axis, color='b',\n",
    "             lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "    plt.plot(x4_axis, y4_axis, color='r',\n",
    "             lw=lw, label='GBFS_adapt',marker=\"o\")\n",
    "    plt.xlabel('number of active features')\n",
    "    plt.ylabel('ranking_precision scores')\n",
    "    plt.title(f'ranking_precision scores v.s. number of active features with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot3 precision @3 v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "GBDTBTt=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                GBDTt[model.attrN,alpha]=max(GBDTt[model.attrN,alpha],model.get_ranking_precision(k=3))\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                GBDTBTt[model.attrN,alpha]=max(GBDTBTt[model.attrN,alpha],model.get_ranking_precision(k=3))\n",
    "            elif model.topk==-1 and model.pen>0: \n",
    "                GBFS[model.attrN,alpha]=max(GBFS[model.attrN,alpha],model.get_ranking_precision(k=3))\n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x1_axis=sorted([idx[0] for idx in GBDTt.keys() if idx[1]==alpha])\n",
    "    y1_axis=[GBDTt[x,alpha] for x in x1_axis]\n",
    "    x2_axis=sorted([idx[0] for idx in GBFS.keys() if idx[1]==alpha])\n",
    "    y2_axis=[GBFS[x,alpha] for x in x2_axis]\n",
    "    x3_axis=sorted([idx[0] for idx in GBDTBTt.keys() if idx[1]==alpha])\n",
    "    y3_axis=[GBDTBTt[x,alpha] for x in x3_axis]\n",
    "    plt.plot(x1_axis, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.plot(x3_axis, y3_axis, color='b',\n",
    "             lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "    plt.xlabel('number of active features')\n",
    "    plt.ylabel('ranking_precision scores')\n",
    "    plt.title(f'ranking_precision scores v.s. number of active features with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot3 precision @5 v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "GBDTBTt=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                GBDTt[model.attrN,alpha]=max(GBDTt[model.attrN,alpha],model.get_ranking_precision(k=5))\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                GBDTBTt[model.attrN,alpha]=max(GBDTBTt[model.attrN,alpha],model.get_ranking_precision(k=5))\n",
    "            elif model.topk==-1 and model.pen>0: \n",
    "                GBFS[model.attrN,alpha]=max(GBFS[model.attrN,alpha],model.get_ranking_precision(k=5))\n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x1_axis=sorted([idx[0] for idx in GBDTt.keys() if idx[1]==alpha])\n",
    "    y1_axis=[GBDTt[x,alpha] for x in x1_axis]\n",
    "    x2_axis=sorted([idx[0] for idx in GBFS.keys() if idx[1]==alpha])\n",
    "    y2_axis=[GBFS[x,alpha] for x in x2_axis]\n",
    "    x3_axis=sorted([idx[0] for idx in GBDTBTt.keys() if idx[1]==alpha])\n",
    "    y3_axis=[GBDTBTt[x,alpha] for x in x3_axis]\n",
    "    plt.plot(x1_axis, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.plot(x3_axis, y3_axis, color='b',\n",
    "             lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "    plt.xlabel('number of active features')\n",
    "    plt.ylabel('ranking_precision scores')\n",
    "    plt.title(f'ranking_precision scores v.s. number of active features with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot 4 precision@k v.s. k for three models that with <=25 variables\n",
    "ks=[2,3,4,5]\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "GBDTBTt=collections.defaultdict(int)\n",
    "GBFS_adaptive=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            for k in ks:\n",
    "                if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                    GBDTt[alpha,k]=max(GBDTt[alpha,k],model.get_ranking_precision(k=k))\n",
    "                elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                    GBDTBTt[alpha,k]=max(GBDTBTt[alpha,k],model.get_ranking_precision(k=k))\n",
    "                elif model.topk==-1 and model.pen>1: \n",
    "                    GBFS[alpha,k]=max(GBFS[alpha,k],model.get_ranking_precision(k=k))\n",
    "                elif model.topk==-1 and model.pen>0:\n",
    "                    GBFS_adaptive[alpha,k]=max(GBFS_adaptive[alpha,k],model.get_ranking_precision(k=k))\n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    y1_axis=[GBDTt[alpha,k] for k in ks]\n",
    "    y2_axis=[GBFS[alpha,k] for k in ks]\n",
    "    y3_axis=[GBDTBTt[alpha,k] for k in ks]\n",
    "    y4_axis=[GBFS_adaptive[alpha,k] for k in ks]\n",
    "    plt.plot(ks, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(ks, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.plot(ks, y3_axis, color='b',\n",
    "             lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "    plt.plot(ks, y4_axis, color='r',\n",
    "             lw=lw, label='GBFS_adapt',marker=\"o\")\n",
    "    plt.xlabel('k as in precision @k')\n",
    "    plt.ylabel('ranking_precision scores')\n",
    "    plt.title(f'ranking_precision scores @k v.s. k with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the best result for each model with attrN<=25 AUC\n",
    "gbdt_auc=[0,0,0,0] # AUC,attrN,pen,alpha\n",
    "gbdtbt_auc=[0,0,0,0]\n",
    "gbfs_auc=[0,0,0,0]\n",
    "gbfsad_auc=[0,0,0,0]\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                gbdt_auc=max(gbdt_auc,[model.get_AUC(),model.attrN,model.pen,model.alpha])\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                gbdtbt_auc=max(gbdtbt_auc,[model.get_AUC(),model.attrN,model.pen,model.alpha])\n",
    "            elif model.topk==-1 and model.pen>1: \n",
    "                gbfs_auc=max(gbfs_auc,[model.get_AUC(),model.attrN,model.pen,model.alpha])\n",
    "            elif model.topk==-1 and model.pen>0:\n",
    "                gbfsad_auc=max(gbfsad_auc,[model.get_AUC(),model.attrN,model.pen,model.alpha])\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbdt_auc : [0.9128164257871372, 19, 0, 0.001]\n",
      "gbdtbt_auc : [0.9122246006485892, 17, 0, 0.01]\n",
      "gbfs_auc : [0.9141814665524568, 25, 14.0, 0.001]\n",
      "gbfsad_auc : [0.9117324537129279, 22, 0.15, 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(f\"gbdt_auc : {gbdt_auc}\")\n",
    "print(f\"gbdtbt_auc : {gbdtbt_auc}\")\n",
    "print(f\"gbfs_auc : {gbfs_auc}\")\n",
    "print(f\"gbfsad_auc : {gbfsad_auc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the best result for each model with attrN<=25 RMSE\n",
    "gbdt_rmse=[float(\"inf\"),0,0,0] # rmse,attrN,pen,alpha\n",
    "gbdtbt_rmse=[float(\"inf\"),0,0,0]\n",
    "gbfs_rmse=[float(\"inf\"),0,0,0]\n",
    "gbfsad_rmse=[float(\"inf\"),0,0,0]\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                gbdt_rmse=min(gbdt_rmse,[model.rmse,model.attrN,model.pen,model.alpha])\n",
    "            elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                gbdtbt_rmse=min(gbdtbt_rmse,[model.rmse,model.attrN,model.pen,model.alpha])\n",
    "            elif model.topk==-1 and model.pen>1: \n",
    "                gbfs_rmse=min(gbfs_rmse,[model.rmse,model.attrN,model.pen,model.alpha])\n",
    "            elif model.topk==-1 and model.pen>0:\n",
    "                gbfsad_rmse=min(gbfsad_rmse,[model.rmse,model.attrN,model.pen,model.alpha])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "gbdt_rmse : [0.278256, 25, 0, 0.0]\n",
      "gbdtbt_rmse : [0.282011, 22, 0, 0.0]\n",
      "gbfs_rmse : [0.280356, 24, 19.0, 0.0]\n",
      "gbfsad_rmse : [0.289981, 22, 0.15, 0.01]\n"
     ]
    }
   ],
   "source": [
    "print(f\"gbdt_rmse : {gbdt_rmse}\")\n",
    "print(f\"gbdtbt_rmse : {gbdtbt_rmse}\")\n",
    "print(f\"gbfs_rmse : {gbfs_rmse}\")\n",
    "print(f\"gbfsad_rmse : {gbfsad_rmse}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## find the best result for each model with attrN<=25 precision @k\n",
    "gbdt_prec={2:[0,0,0,0],3:[0,0,0,0],4:[0,0,0,0]}  # prec,attrN,pen,alpha\n",
    "gbdtbt_prec={2:[0,0,0,0],3:[0,0,0,0],4:[0,0,0,0]} \n",
    "gbfs_prec={2:[0,0,0,0],3:[0,0,0,0],4:[0,0,0,0]} \n",
    "gbfsad_prec={2:[0,0,0,0],3:[0,0,0,0],4:[0,0,0,0]} \n",
    "ks=[2,3,4]\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.attrN<=25:\n",
    "            for k in ks:\n",
    "                if model.pen==0 and model.topk>0 and model.name==\"GBDT\":\n",
    "                    gbdt_prec[k]=max(gbdt_prec[k],[model.get_ranking_precision(k=k),model.attrN,model.pen,model.alpha])\n",
    "                elif model.pen==0 and model.topk>0 and model.name==\"GBDTBT\":\n",
    "                    gbdtbt_prec[k]=max(gbdtbt_prec[k],[model.get_ranking_precision(k=k),model.attrN,model.pen,model.alpha])\n",
    "                elif model.topk==-1 and model.pen>1: \n",
    "                    gbfs_prec[k]=max(gbfs_prec[k],[model.get_ranking_precision(k=k),model.attrN,model.pen,model.alpha])\n",
    "                elif model.topk==-1 and model.pen>0:\n",
    "                    gbfsad_prec[k]=max(gbfsad_prec[k],[model.get_ranking_precision(k=k),model.attrN,model.pen,model.alpha])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"gbdt_prec : {gbdt_prec}\")\n",
    "print(f\"gbdtbt_prec : {gbdtbt_prec}\")\n",
    "print(f\"gbfs_prec : {gbfs_prec}\")\n",
    "print(f\"gbfsad_prec : {gbfsad_prec}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## for madelon dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "result_path='result/madelon/'\n",
    "attr_total=500"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "## preprocess\n",
    "\n",
    "filenames_result=listdir(result_path)\n",
    "trueY=pd.read_csv(result_path+\"trueY.txt\",header=None)[0]\n",
    "#kw=pd.read_csv(result_path+\"keyword.txt\",header=None)[0]\n",
    "try:\n",
    "    number_unused=len(pd.read_csv(result_path+\"preprocess_unused.txt\",header=None))\n",
    "except:\n",
    "    number_unused=0\n",
    "attr_init_number=attr_total-number_unused"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# store results when go through all files in result folder\n",
    "# index result like [(mu,alpha)]\n",
    "GBFS_dict=collections.defaultdict(dict) # store preds,attrN for different mu and alpha\n",
    "GBDTt_dict={} # indexed by alpha,topk\n",
    "for filename in filenames_result:\n",
    "    last_dot=filename.rfind(\".\")\n",
    "    fname,fext=filename[:last_dot],filename[last_dot+1:]\n",
    "    if fext==\"txt\" and \"_alpha\" in fname:\n",
    "        alpha=float(fname[fname.index(\"_alpha\")+6:])\n",
    "        if \"_preds\" in fname:\n",
    "            preds=pd.read_csv(result_path+filename,header=None)[0]\n",
    "            if \"GBFSt\" in fname:\n",
    "                attrN=int(fname[5:fname.index(\"_mu\")])\n",
    "                GBDTt_dict[alpha,attrN]=preds\n",
    "            else:\n",
    "                idx=fname.index(\"_mu\")\n",
    "                mu=float(fname[idx+3:fname.index(\"_preds\")])\n",
    "                GBFS_dict[mu,alpha][\"preds\"]=preds\n",
    "        elif \"feature_scores_\" in fname:\n",
    "            tmp=pd.read_csv(result_path+filename,header=None)[0][0] # the first line of feature_score reports attrN\n",
    "            attrN=int(tmp.split()[-1])\n",
    "            if \"_mu\" in fname:\n",
    "                idx=fname.index(\"_mu\")\n",
    "                mu=float(fname[idx+3:fname.index(\"_alpha\")])\n",
    "            else:\n",
    "                mu=0\n",
    "            GBFS_dict[mu,alpha][\"attrN\"]=attrN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put result together\n",
    "model_results=collections.defaultdict(list) # indexed by mu,alpha\n",
    "# GBFS model\n",
    "for mu,alpha in GBFS_dict:\n",
    "    try:\n",
    "        attrN=GBFS_dict[mu,alpha][\"attrN\"]\n",
    "        preds=GBFS_dict[mu,alpha][\"preds\"]\n",
    "        model_results[mu,alpha].append(Model(penalty=mu,alpha=alpha,topk=-1,attrN=attrN,preds=preds))\n",
    "    except:\n",
    "        print(\"not ready\")\n",
    "# GBDTt model\n",
    "for alpha,topk in GBDTt_dict:\n",
    "    preds=GBDTt_dict[alpha,topk]\n",
    "    model_results[0,alpha].append(Model(alpha=alpha,topk=topk,attrN=topk,preds=preds))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mus=sorted(set(idx[0] for idx in GBFS_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alphas=sorted(set(idx[1] for idx in GBFS_dict.keys()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot1 attrN v.s. mus for GBFS\n",
    "for alpha in alphas:\n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x_axis=mus\n",
    "    y_axis=[GBFS_dict[mu,alpha][\"attrN\"] for mu in x_axis]\n",
    "    plt.plot(x_axis, y_axis, color='b',marker=\"o\",\n",
    "             lw=lw, label='GBFS')\n",
    "    #plt.xlim([0.0, max(x_axis)])\n",
    "    #plt.ylim([20, 100])\n",
    "    plt.xlabel('Penalty parameter mu')\n",
    "    plt.ylabel('Number of active features')\n",
    "    plt.title(f'Number of active features v.s. Penalty parameter mu with alpha={alpha}')\n",
    "    plt.legend(loc=\"upper right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# plot2 AUC_ROC v.s. attrN (for best score with the given attrN for GBFS) given alpha\n",
    "\n",
    "GBDTt=collections.defaultdict(int)\n",
    "GBFS=collections.defaultdict(int)\n",
    "for mu,alpha in model_results:\n",
    "    for model in model_results[mu,alpha]:\n",
    "        if model.pen==0 and model.topk>0:\n",
    "            GBDTt[model.attrN,alpha]=max(GBDTt[model.attrN,alpha],model.get_AUC())\n",
    "        elif model.topk==-1: \n",
    "            GBFS[model.attrN,alpha]=max(GBFS[model.attrN,alpha],model.get_AUC())\n",
    "for alpha in alphas:        \n",
    "    plt.figure()\n",
    "    lw = 2\n",
    "    x1_axis=sorted([idx[0] for idx in GBDTt.keys() if idx[1]==alpha])\n",
    "    y1_axis=[GBDTt[x,alpha] for x in x1_axis]\n",
    "    x2_axis=sorted([idx[0] for idx in GBFS.keys() if idx[1]==alpha])\n",
    "    y2_axis=[GBFS[x,alpha] for x in x2_axis]\n",
    "    plt.plot(x1_axis, y1_axis, color='g',\n",
    "             lw=lw, label='GBDTt',marker=\"o\")\n",
    "    plt.plot(x2_axis, y2_axis, color='darkorange',\n",
    "             lw=lw, label='GBFS',marker=\"o\")\n",
    "    plt.xlim([0,45])\n",
    "    #plt.ylim([0.93, 0.95])\n",
    "    plt.xlabel('number of active features')\n",
    "    plt.ylabel('AUC_ROC scores')\n",
    "    plt.title(f'AUC_ROC scores v.s. number of active features with alpha={alpha}')\n",
    "    plt.legend(loc=\"lower right\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation matrix:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [],
   "source": [
    "# us\n",
    "train=pd.read_csv(\"data/us_train.tsv\",sep=\"\\t\")\n",
    "GBFS=pd.read_csv(\"result/us/tuned/GBFS_model_feature_scores_mu8_alpha0.05_shrink0.1_itern100_attrn20_rms0.232841.txt\",header=None)[0]\n",
    "GBDTBTt=pd.read_csv(\"result/us/tuned/GBDTBTt_feature_scores_mu0_alpha0.02_shrink0.05_itern200_attrn20_rms0.236866.txt\",header=None)[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBFS_f=[]\n",
    "GBDTBTt_f=[]\n",
    "for line in GBFS[2:]:\n",
    "    tmp=line.split(\"\\t\")\n",
    "    if len(tmp)==2 and float(tmp[1])>0:\n",
    "        GBFS_f.append(tmp[0])\n",
    "for line in GBDTBTt[2:]:\n",
    "    tmp=line.split(\"\\t\")\n",
    "    if len(tmp)==2 and float(tmp[1])>0:\n",
    "        GBDTBTt_f.append(tmp[0])\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'cvrg_storecontextname',\n",
       " 'dp_keyword_hidden_attributes_only_match',\n",
       " 'field_weighted_proximity',\n",
       " 'length_normalized_termdoc',\n",
       " 'non_generickeywords_match',\n",
       " 'num_query_groups_percentile',\n",
       " 'phrasedoc_score',\n",
       " 'qba_score',\n",
       " 'quer_numdigterms',\n",
       " 'quer_specificity_v2',\n",
       " 'query_asin_coec',\n",
       " 'query_entity_price_ratio'}"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "set(GBFS_f).intersection(set(GBDTBTt_f))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBFS_f_cols=train[GBFS_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBDTBTt_f_cols=train[GBDTBTt_f]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBDTBTt_corr=GBDTBTt_f_cols.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "GBFS_corr=GBFS_f_cols.corr()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "query_asin_coec\n",
      "query_asin_aoea\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "sums=0\n",
    "maxs=0\n",
    "abs_corrs_gbfs=[]\n",
    "for name in GBFS_corr:\n",
    "    for num in GBFS_corr[name]:\n",
    "        if not np.isnan(num) and num!=1:\n",
    "            if abs(num)>=0.9:\n",
    "                print(name)\n",
    "            abs_corrs_gbfs.append(abs(num))\n",
    "            maxs=max(maxs,abs(num))\n",
    "            sums+=abs(num)\n",
    "            cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_corrs_gbfs.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_corr: 0.13988450728623192 max_abs_corr: 0.9719564063264122\n"
     ]
    }
   ],
   "source": [
    "print(f'mean_corr: {sums/cnt} max_abs_corr: {maxs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "qu_match_artist\n",
      "num_query_groups_percentile\n",
      "has_artist\n",
      "query_asin_coec\n",
      "query_percentile_tail_clipped\n",
      "query_asin_poep\n"
     ]
    }
   ],
   "source": [
    "cnt=0\n",
    "sums=0\n",
    "abs_corrs_gbdt=[]\n",
    "for name in GBDTBTt_corr:\n",
    "    for num in GBDTBTt_corr[name]:\n",
    "        if not np.isnan(num) and num!=1:\n",
    "            if abs(num)>0.9:\n",
    "                print(name)\n",
    "            abs_corrs_gbdt.append(abs(num))\n",
    "            maxs=max(maxs,abs(num))\n",
    "            sums+=abs(num)\n",
    "            cnt+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "abs_corrs_gbdt.sort(reverse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "mean_corr: 0.15590503891545257 max_abs_corr: 0.9831167259143877\n"
     ]
    }
   ],
   "source": [
    "print(f'mean_corr: {sums/cnt} max_abs_corr: {maxs}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9831167259143877,\n",
       " 0.9831167259143877,\n",
       " 0.9644029485877654,\n",
       " 0.9644029485877654,\n",
       " 0.9425741330139055,\n",
       " 0.9425741330139055,\n",
       " 0.8999070737572407,\n",
       " 0.8999070737572407,\n",
       " 0.8896462477376731,\n",
       " 0.8896462477376731,\n",
       " 0.8444348439997211,\n",
       " 0.8444348439997211,\n",
       " 0.7807043628344955,\n",
       " 0.7807043628344955,\n",
       " 0.7671015800991614,\n",
       " 0.7671015800991614,\n",
       " 0.7323129273988809,\n",
       " 0.7323129273988809,\n",
       " 0.7222127751874303,\n",
       " 0.7222127751874303,\n",
       " 0.7123353574266661,\n",
       " 0.7123353574266661,\n",
       " 0.6949279709450285,\n",
       " 0.6949279709450285,\n",
       " 0.6920522170986428,\n",
       " 0.6920522170986428,\n",
       " 0.6704761640544649,\n",
       " 0.6704761640544649,\n",
       " 0.4662914885148747,\n",
       " 0.4662914885148747,\n",
       " 0.43001144890965376,\n",
       " 0.43001144890965376,\n",
       " 0.39123319375057614,\n",
       " 0.39123319375057614,\n",
       " 0.38809887958178124,\n",
       " 0.38809887958178124,\n",
       " 0.3660730362396617,\n",
       " 0.3660730362396617,\n",
       " 0.35677597126918037,\n",
       " 0.35677597126918037,\n",
       " 0.3531667606363549,\n",
       " 0.3531667606363549,\n",
       " 0.34279946315189114,\n",
       " 0.34279946315189114,\n",
       " 0.34068994038015465,\n",
       " 0.34068994038015465,\n",
       " 0.32533637643991664,\n",
       " 0.32533637643991664,\n",
       " 0.32432140546374605,\n",
       " 0.32432140546374605,\n",
       " 0.3160368222422102,\n",
       " 0.3160368222422102,\n",
       " 0.30287646625859715,\n",
       " 0.30287646625859715,\n",
       " 0.29959469333548483,\n",
       " 0.29959469333548483,\n",
       " 0.29484769247616915,\n",
       " 0.29484769247616915,\n",
       " 0.29233792032366646,\n",
       " 0.29233792032366646,\n",
       " 0.2820295525450771,\n",
       " 0.2820295525450771,\n",
       " 0.27417521321226695,\n",
       " 0.27417521321226695,\n",
       " 0.2685071674469823,\n",
       " 0.2685071674469823,\n",
       " 0.25932462059457967,\n",
       " 0.25932462059457967,\n",
       " 0.2574434051507716,\n",
       " 0.2574434051507716,\n",
       " 0.25643810540650513,\n",
       " 0.25643810540650513,\n",
       " 0.2530965535166097,\n",
       " 0.2530965535166097,\n",
       " 0.24699996413752642,\n",
       " 0.24699996413752642,\n",
       " 0.24270795813715557,\n",
       " 0.24270795813715557,\n",
       " 0.2359285831136434,\n",
       " 0.2359285831136434,\n",
       " 0.21179188594276074,\n",
       " 0.21179188594276074,\n",
       " 0.20717344192013132,\n",
       " 0.20717344192013132,\n",
       " 0.2070193208677872,\n",
       " 0.2070193208677872,\n",
       " 0.20605524842741657,\n",
       " 0.20605524842741657,\n",
       " 0.1840555108769477,\n",
       " 0.1840555108769477,\n",
       " 0.18383141254763355,\n",
       " 0.18383141254763355,\n",
       " 0.17826973621444467,\n",
       " 0.17826973621444467,\n",
       " 0.17804732228070155,\n",
       " 0.17804732228070155,\n",
       " 0.17741336614194597,\n",
       " 0.17741336614194597,\n",
       " 0.1701926144432213,\n",
       " 0.1701926144432213,\n",
       " 0.16977573487815398,\n",
       " 0.16977573487815398,\n",
       " 0.16941250436761818,\n",
       " 0.16941250436761818,\n",
       " 0.1661612952048262,\n",
       " 0.1661612952048262,\n",
       " 0.16365669711735426,\n",
       " 0.16365669711735426,\n",
       " 0.16099365698013007,\n",
       " 0.16099365698013007,\n",
       " 0.15485045128355673,\n",
       " 0.15485045128355673,\n",
       " 0.15156383991739852,\n",
       " 0.15156383991739852,\n",
       " 0.14664150988986518,\n",
       " 0.14664150988986518,\n",
       " 0.14238144466784175,\n",
       " 0.14238144466784175,\n",
       " 0.13923099101747366,\n",
       " 0.13923099101747366,\n",
       " 0.13660307015771486,\n",
       " 0.13660307015771486,\n",
       " 0.13540677159997855,\n",
       " 0.13540677159997855,\n",
       " 0.1354025193374435,\n",
       " 0.1354025193374435,\n",
       " 0.135060899318818,\n",
       " 0.135060899318818,\n",
       " 0.123791554916721,\n",
       " 0.123791554916721,\n",
       " 0.11967645441735314,\n",
       " 0.11967645441735314,\n",
       " 0.11927030457780245,\n",
       " 0.11927030457780245,\n",
       " 0.11400265027670185,\n",
       " 0.11400265027670185,\n",
       " 0.1068223362506225,\n",
       " 0.1068223362506225,\n",
       " 0.09799655412202407,\n",
       " 0.09799655412202407,\n",
       " 0.09781182946705791,\n",
       " 0.09781182946705791,\n",
       " 0.09441455591105807,\n",
       " 0.09441455591105807,\n",
       " 0.09383529105717595,\n",
       " 0.09383529105717595,\n",
       " 0.09300048132969685,\n",
       " 0.09300048132969685,\n",
       " 0.09288091776146562,\n",
       " 0.09288091776146562,\n",
       " 0.0914752783947901,\n",
       " 0.0914752783947901,\n",
       " 0.08808420096487257,\n",
       " 0.08808420096487257,\n",
       " 0.0874827609528418,\n",
       " 0.0874827609528418,\n",
       " 0.08440029737868794,\n",
       " 0.08440029737868794,\n",
       " 0.08413880784444194,\n",
       " 0.08413880784444194,\n",
       " 0.07690732424659238,\n",
       " 0.07690732424659238,\n",
       " 0.07483353981072219,\n",
       " 0.07483353981072219,\n",
       " 0.07196635659216828,\n",
       " 0.07196635659216828,\n",
       " 0.06867914821200903,\n",
       " 0.06867914821200903,\n",
       " 0.0681161393175603,\n",
       " 0.0681161393175603,\n",
       " 0.06789962003946816,\n",
       " 0.06789962003946816,\n",
       " 0.06410930686556195,\n",
       " 0.06410930686556195,\n",
       " 0.061964272717940826,\n",
       " 0.061964272717940826,\n",
       " 0.06192406149283316,\n",
       " 0.06192406149283316,\n",
       " 0.05868533126495562,\n",
       " 0.05868533126495562,\n",
       " 0.05623801305724474,\n",
       " 0.05623801305724474,\n",
       " 0.05329907360587678,\n",
       " 0.05329907360587678,\n",
       " 0.05264965285811461,\n",
       " 0.05264965285811461,\n",
       " 0.052541590533134334,\n",
       " 0.052541590533134334,\n",
       " 0.05091500167793137,\n",
       " 0.05091500167793137,\n",
       " 0.0503559673253728,\n",
       " 0.0503559673253728,\n",
       " 0.04867918950053086,\n",
       " 0.04867918950053086,\n",
       " 0.0472762130767091,\n",
       " 0.0472762130767091,\n",
       " 0.04706580728902402,\n",
       " 0.04706580728902402,\n",
       " 0.047055275102524094,\n",
       " 0.047055275102524094,\n",
       " 0.04702275287055614,\n",
       " 0.04702275287055614,\n",
       " 0.046061538996545276,\n",
       " 0.046061538996545276,\n",
       " 0.04594577861894391,\n",
       " 0.04594577861894391,\n",
       " 0.04541349698230415,\n",
       " 0.04541349698230415,\n",
       " 0.04532738649918741,\n",
       " 0.04532738649918741,\n",
       " 0.04499791754078449,\n",
       " 0.04499791754078449,\n",
       " 0.043845564091992306,\n",
       " 0.043845564091992306,\n",
       " 0.04356768214815207,\n",
       " 0.04356768214815207,\n",
       " 0.04201077524451836,\n",
       " 0.04201077524451836,\n",
       " 0.04004032484122964,\n",
       " 0.04004032484122964,\n",
       " 0.037106318887540415,\n",
       " 0.037106318887540415,\n",
       " 0.03505777500228497,\n",
       " 0.03505777500228497,\n",
       " 0.03442354218188278,\n",
       " 0.03442354218188278,\n",
       " 0.03315232837846433,\n",
       " 0.03315232837846433,\n",
       " 0.030373634818260442,\n",
       " 0.030373634818260442,\n",
       " 0.027710482138178158,\n",
       " 0.027710482138178158,\n",
       " 0.02746394133839402,\n",
       " 0.02746394133839402,\n",
       " 0.025902588804448314,\n",
       " 0.025902588804448314,\n",
       " 0.025537705770565126,\n",
       " 0.025537705770565126,\n",
       " 0.025267453505927268,\n",
       " 0.025267453505927268,\n",
       " 0.02349974739011132,\n",
       " 0.02349974739011132,\n",
       " 0.022330884053727986,\n",
       " 0.022330884053727986,\n",
       " 0.022081045180934993,\n",
       " 0.022081045180934993,\n",
       " 0.021483796537395648,\n",
       " 0.021483796537395648,\n",
       " 0.021048152712197125,\n",
       " 0.021048152712197125,\n",
       " 0.02020776642669809,\n",
       " 0.02020776642669809,\n",
       " 0.020105949056759522,\n",
       " 0.020105949056759522,\n",
       " 0.01955876499351527,\n",
       " 0.01955876499351527,\n",
       " 0.01937281085667698,\n",
       " 0.01937281085667698,\n",
       " 0.0192253724776519,\n",
       " 0.0192253724776519,\n",
       " 0.015567643242453097,\n",
       " 0.015567643242453097,\n",
       " 0.015299792087311751,\n",
       " 0.015299792087311751,\n",
       " 0.014576013878634098,\n",
       " 0.014576013878634098,\n",
       " 0.014348289804552735,\n",
       " 0.014348289804552735,\n",
       " 0.014213691882651066,\n",
       " 0.014213691882651066,\n",
       " 0.014173316138022746,\n",
       " 0.014173316138022746,\n",
       " 0.01358291776804031,\n",
       " 0.01358291776804031,\n",
       " 0.013276084418013413,\n",
       " 0.013276084418013413,\n",
       " 0.01289592255350103,\n",
       " 0.01289592255350103,\n",
       " 0.012814644727186643,\n",
       " 0.012814644727186643,\n",
       " 0.011532247418093772,\n",
       " 0.011532247418093772,\n",
       " 0.011177052525995884,\n",
       " 0.011177052525995884,\n",
       " 0.011135001367546749,\n",
       " 0.011135001367546749,\n",
       " 0.010775681956464148,\n",
       " 0.010775681956464148,\n",
       " 0.010767669599226268,\n",
       " 0.010767669599226268,\n",
       " 0.010523902145452523,\n",
       " 0.010523902145452523,\n",
       " 0.010384372310934467,\n",
       " 0.010384372310934467,\n",
       " 0.010214506469530843,\n",
       " 0.010214506469530843,\n",
       " 0.009867235921561692,\n",
       " 0.009867235921561692,\n",
       " 0.009626061601942832,\n",
       " 0.009626061601942832,\n",
       " 0.00927457973042892,\n",
       " 0.00927457973042892,\n",
       " 0.009128882959334223,\n",
       " 0.009128882959334223,\n",
       " 0.008854243003819227,\n",
       " 0.008854243003819227,\n",
       " 0.008817363221548554,\n",
       " 0.008817363221548554,\n",
       " 0.00878804753932856,\n",
       " 0.00878804753932856,\n",
       " 0.008682927786671147,\n",
       " 0.008682927786671147,\n",
       " 0.008132764578111004,\n",
       " 0.008132764578111004,\n",
       " 0.007652503431606457,\n",
       " 0.007652503431606457,\n",
       " 0.007469461134870712,\n",
       " 0.007469461134870712,\n",
       " 0.00743311588551188,\n",
       " 0.00743311588551188,\n",
       " 0.00636615639492341,\n",
       " 0.00636615639492341,\n",
       " 0.005903098725067104,\n",
       " 0.005903098725067104,\n",
       " 0.005828877714090633,\n",
       " 0.005828877714090633,\n",
       " 0.00546852023034706,\n",
       " 0.00546852023034706,\n",
       " 0.005387443744954311,\n",
       " 0.005387443744954311,\n",
       " 0.004716683415591555,\n",
       " 0.004716683415591555,\n",
       " 0.004493636361143582,\n",
       " 0.004493636361143582,\n",
       " 0.004180139111702703,\n",
       " 0.004180139111702703,\n",
       " 0.003997325228391945,\n",
       " 0.003997325228391945,\n",
       " 0.003852757994850127,\n",
       " 0.003852757994850127,\n",
       " 0.003579177418502133,\n",
       " 0.003579177418502133,\n",
       " 0.003256467260105698,\n",
       " 0.003256467260105698,\n",
       " 0.002802952584831373,\n",
       " 0.002802952584831373,\n",
       " 0.0023776044949172324,\n",
       " 0.0023776044949172324,\n",
       " 0.0018864995779470943,\n",
       " 0.0018864995779470943,\n",
       " 0.00034744611335148554,\n",
       " 0.00034744611335148554,\n",
       " 3.347032897190087e-05,\n",
       " 3.347032897190087e-05]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_corrs_gbdt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.9719564063264122,\n",
       " 0.9719564063264122,\n",
       " 0.8444348439997211,\n",
       " 0.8444348439997211,\n",
       " 0.7786949774555105,\n",
       " 0.7786949774555105,\n",
       " 0.7671015800991614,\n",
       " 0.7671015800991614,\n",
       " 0.7282203378110533,\n",
       " 0.7282203378110533,\n",
       " 0.7222127751874303,\n",
       " 0.7222127751874303,\n",
       " 0.7103644130748313,\n",
       " 0.7103644130748313,\n",
       " 0.6888047418475048,\n",
       " 0.6888047418475048,\n",
       " 0.6704761640544649,\n",
       " 0.6704761640544649,\n",
       " 0.6541016825653446,\n",
       " 0.6541016825653446,\n",
       " 0.6437531863430472,\n",
       " 0.6437531863430472,\n",
       " 0.4931042767012368,\n",
       " 0.4931042767012368,\n",
       " 0.4606109663026968,\n",
       " 0.4606109663026968,\n",
       " 0.43001144890965376,\n",
       " 0.43001144890965376,\n",
       " 0.39123319375057614,\n",
       " 0.39123319375057614,\n",
       " 0.38809887958178124,\n",
       " 0.38809887958178124,\n",
       " 0.3766004648714632,\n",
       " 0.3766004648714632,\n",
       " 0.37546626685115125,\n",
       " 0.37546626685115125,\n",
       " 0.3531667606363549,\n",
       " 0.3531667606363549,\n",
       " 0.3267777947466149,\n",
       " 0.3267777947466149,\n",
       " 0.3160368222422102,\n",
       " 0.3160368222422102,\n",
       " 0.30991301162778107,\n",
       " 0.30991301162778107,\n",
       " 0.308285143699889,\n",
       " 0.308285143699889,\n",
       " 0.30287646625859715,\n",
       " 0.30287646625859715,\n",
       " 0.29959469333548483,\n",
       " 0.29959469333548483,\n",
       " 0.2820295525450771,\n",
       " 0.2820295525450771,\n",
       " 0.28144570926886997,\n",
       " 0.28144570926886997,\n",
       " 0.2790641352509358,\n",
       " 0.2790641352509358,\n",
       " 0.27026066125506293,\n",
       " 0.27026066125506293,\n",
       " 0.2667572115650862,\n",
       " 0.2667572115650862,\n",
       " 0.2605089258619674,\n",
       " 0.2605089258619674,\n",
       " 0.2574434051507716,\n",
       " 0.2574434051507716,\n",
       " 0.2530965535166097,\n",
       " 0.2530965535166097,\n",
       " 0.25287874328219545,\n",
       " 0.25287874328219545,\n",
       " 0.25070060030223534,\n",
       " 0.25070060030223534,\n",
       " 0.24270795813715557,\n",
       " 0.24270795813715557,\n",
       " 0.2180614274893931,\n",
       " 0.2180614274893931,\n",
       " 0.21179188594276074,\n",
       " 0.21179188594276074,\n",
       " 0.20605524842741657,\n",
       " 0.20605524842741657,\n",
       " 0.1963449311859078,\n",
       " 0.1963449311859078,\n",
       " 0.1951589108186648,\n",
       " 0.1951589108186648,\n",
       " 0.18622233835945978,\n",
       " 0.18622233835945978,\n",
       " 0.18562757069909858,\n",
       " 0.18562757069909858,\n",
       " 0.1840555108769477,\n",
       " 0.1840555108769477,\n",
       " 0.17897742249006116,\n",
       " 0.17897742249006116,\n",
       " 0.17804732228070155,\n",
       " 0.17804732228070155,\n",
       " 0.17742631071686082,\n",
       " 0.17742631071686082,\n",
       " 0.17408966735633283,\n",
       " 0.17408966735633283,\n",
       " 0.17391987291530336,\n",
       " 0.17391987291530336,\n",
       " 0.17227753536624063,\n",
       " 0.17227753536624063,\n",
       " 0.17176367873407092,\n",
       " 0.17176367873407092,\n",
       " 0.17046705315567212,\n",
       " 0.17046705315567212,\n",
       " 0.16977573487815398,\n",
       " 0.16977573487815398,\n",
       " 0.16941250436761818,\n",
       " 0.16941250436761818,\n",
       " 0.1661612952048262,\n",
       " 0.1661612952048262,\n",
       " 0.16365669711735426,\n",
       " 0.16365669711735426,\n",
       " 0.16099365698013007,\n",
       " 0.16099365698013007,\n",
       " 0.15519684212643184,\n",
       " 0.15519684212643184,\n",
       " 0.15485045128355673,\n",
       " 0.15485045128355673,\n",
       " 0.14804666581895443,\n",
       " 0.14804666581895443,\n",
       " 0.13923099101747366,\n",
       " 0.13923099101747366,\n",
       " 0.13540677159997855,\n",
       " 0.13540677159997855,\n",
       " 0.1354025193374435,\n",
       " 0.1354025193374435,\n",
       " 0.135060899318818,\n",
       " 0.135060899318818,\n",
       " 0.1330382938361821,\n",
       " 0.1330382938361821,\n",
       " 0.12921681690464712,\n",
       " 0.12921681690464712,\n",
       " 0.12755114406789075,\n",
       " 0.12755114406789075,\n",
       " 0.1197155391434799,\n",
       " 0.1197155391434799,\n",
       " 0.11952131524613774,\n",
       " 0.11952131524613774,\n",
       " 0.10913552456879201,\n",
       " 0.10913552456879201,\n",
       " 0.1068223362506225,\n",
       " 0.1068223362506225,\n",
       " 0.10067474295498235,\n",
       " 0.10067474295498235,\n",
       " 0.09838487215435919,\n",
       " 0.09838487215435919,\n",
       " 0.09781182946705791,\n",
       " 0.09781182946705791,\n",
       " 0.09387542225381536,\n",
       " 0.09387542225381536,\n",
       " 0.09300048132969685,\n",
       " 0.09300048132969685,\n",
       " 0.09246848252398608,\n",
       " 0.09246848252398608,\n",
       " 0.09220041275919826,\n",
       " 0.09220041275919826,\n",
       " 0.0914752783947901,\n",
       " 0.0914752783947901,\n",
       " 0.09043985507568864,\n",
       " 0.09043985507568864,\n",
       " 0.08738769231408257,\n",
       " 0.08738769231408257,\n",
       " 0.08651423130444044,\n",
       " 0.08651423130444044,\n",
       " 0.08413880784444194,\n",
       " 0.08413880784444194,\n",
       " 0.08102107494548946,\n",
       " 0.08102107494548946,\n",
       " 0.08092145713398635,\n",
       " 0.08092145713398635,\n",
       " 0.08010475291599672,\n",
       " 0.08010475291599672,\n",
       " 0.0798039282063377,\n",
       " 0.0798039282063377,\n",
       " 0.07748573628157125,\n",
       " 0.07748573628157125,\n",
       " 0.07690732424659238,\n",
       " 0.07690732424659238,\n",
       " 0.07483353981072219,\n",
       " 0.07483353981072219,\n",
       " 0.07359687685969753,\n",
       " 0.07359687685969753,\n",
       " 0.0711625099196638,\n",
       " 0.0711625099196638,\n",
       " 0.0689838188180744,\n",
       " 0.0689838188180744,\n",
       " 0.06867914821200903,\n",
       " 0.06867914821200903,\n",
       " 0.0681161393175603,\n",
       " 0.0681161393175603,\n",
       " 0.06566163627085968,\n",
       " 0.06566163627085968,\n",
       " 0.06561073275305397,\n",
       " 0.06561073275305397,\n",
       " 0.063863919399003,\n",
       " 0.063863919399003,\n",
       " 0.06373770951822076,\n",
       " 0.06373770951822076,\n",
       " 0.060828557302356014,\n",
       " 0.060828557302356014,\n",
       " 0.06068690802529042,\n",
       " 0.06068690802529042,\n",
       " 0.05981194897482145,\n",
       " 0.05981194897482145,\n",
       " 0.059268436590686875,\n",
       " 0.059268436590686875,\n",
       " 0.058039070414532,\n",
       " 0.058039070414532,\n",
       " 0.05798834983730569,\n",
       " 0.05798834983730569,\n",
       " 0.05329907360587678,\n",
       " 0.05329907360587678,\n",
       " 0.052541590533134334,\n",
       " 0.052541590533134334,\n",
       " 0.05174241783936725,\n",
       " 0.05174241783936725,\n",
       " 0.051634694656286714,\n",
       " 0.051634694656286714,\n",
       " 0.05091500167793137,\n",
       " 0.05091500167793137,\n",
       " 0.049874895751730194,\n",
       " 0.049874895751730194,\n",
       " 0.04897974907066161,\n",
       " 0.04897974907066161,\n",
       " 0.04867918950053086,\n",
       " 0.04867918950053086,\n",
       " 0.0472762130767091,\n",
       " 0.0472762130767091,\n",
       " 0.047055275102524094,\n",
       " 0.047055275102524094,\n",
       " 0.04702275287055614,\n",
       " 0.04702275287055614,\n",
       " 0.0456397840628726,\n",
       " 0.0456397840628726,\n",
       " 0.04356768214815207,\n",
       " 0.04356768214815207,\n",
       " 0.04292258120535112,\n",
       " 0.04292258120535112,\n",
       " 0.04201077524451836,\n",
       " 0.04201077524451836,\n",
       " 0.041770261104875174,\n",
       " 0.041770261104875174,\n",
       " 0.0413587380589864,\n",
       " 0.0413587380589864,\n",
       " 0.04004032484122964,\n",
       " 0.04004032484122964,\n",
       " 0.039441768752718244,\n",
       " 0.039441768752718244,\n",
       " 0.03939371155142468,\n",
       " 0.03939371155142468,\n",
       " 0.037932600020494985,\n",
       " 0.037932600020494985,\n",
       " 0.037106318887540415,\n",
       " 0.037106318887540415,\n",
       " 0.03703398303047451,\n",
       " 0.03703398303047451,\n",
       " 0.036040148767235616,\n",
       " 0.036040148767235616,\n",
       " 0.035108187286414516,\n",
       " 0.035108187286414516,\n",
       " 0.03442354218188278,\n",
       " 0.03442354218188278,\n",
       " 0.03402403000335625,\n",
       " 0.03402403000335625,\n",
       " 0.034000481045980774,\n",
       " 0.034000481045980774,\n",
       " 0.03315232837846433,\n",
       " 0.03315232837846433,\n",
       " 0.032686157586239585,\n",
       " 0.032686157586239585,\n",
       " 0.032637837175772656,\n",
       " 0.032637837175772656,\n",
       " 0.03206011752977399,\n",
       " 0.03206011752977399,\n",
       " 0.03147855633538761,\n",
       " 0.03147855633538761,\n",
       " 0.030373634818260442,\n",
       " 0.030373634818260442,\n",
       " 0.03035442949219912,\n",
       " 0.03035442949219912,\n",
       " 0.029649389031514366,\n",
       " 0.029649389031514366,\n",
       " 0.02746394133839402,\n",
       " 0.02746394133839402,\n",
       " 0.025350400768856838,\n",
       " 0.025350400768856838,\n",
       " 0.025245601783030692,\n",
       " 0.025245601783030692,\n",
       " 0.024493723051182942,\n",
       " 0.024493723051182942,\n",
       " 0.02349974739011132,\n",
       " 0.02349974739011132,\n",
       " 0.022943994384463297,\n",
       " 0.022943994384463297,\n",
       " 0.022673500786158766,\n",
       " 0.022673500786158766,\n",
       " 0.022433826268652226,\n",
       " 0.022433826268652226,\n",
       " 0.022330884053727986,\n",
       " 0.022330884053727986,\n",
       " 0.020105949056759522,\n",
       " 0.020105949056759522,\n",
       " 0.019307404406108133,\n",
       " 0.019307404406108133,\n",
       " 0.018804591113861093,\n",
       " 0.018804591113861093,\n",
       " 0.018397065577676362,\n",
       " 0.018397065577676362,\n",
       " 0.018318500291240835,\n",
       " 0.018318500291240835,\n",
       " 0.017678871433332504,\n",
       " 0.017678871433332504,\n",
       " 0.016765100424949463,\n",
       " 0.016765100424949463,\n",
       " 0.016256599871910908,\n",
       " 0.016256599871910908,\n",
       " 0.015746153296417504,\n",
       " 0.015746153296417504,\n",
       " 0.014576013878634098,\n",
       " 0.014576013878634098,\n",
       " 0.014489276320514076,\n",
       " 0.014489276320514076,\n",
       " 0.014213691882651066,\n",
       " 0.014213691882651066,\n",
       " 0.014173316138022746,\n",
       " 0.014173316138022746,\n",
       " 0.014082145577688294,\n",
       " 0.014082145577688294,\n",
       " 0.01358291776804031,\n",
       " 0.01358291776804031,\n",
       " 0.011811705807797111,\n",
       " 0.011811705807797111,\n",
       " 0.011614399128421594,\n",
       " 0.011614399128421594,\n",
       " 0.010888142640942294,\n",
       " 0.010888142640942294,\n",
       " 0.009762068556905356,\n",
       " 0.009762068556905356,\n",
       " 0.00927457973042892,\n",
       " 0.00927457973042892,\n",
       " 0.009214265425022947,\n",
       " 0.009214265425022947,\n",
       " 0.009128882959334223,\n",
       " 0.009128882959334223,\n",
       " 0.009049969632724336,\n",
       " 0.009049969632724336,\n",
       " 0.008817363221548554,\n",
       " 0.008817363221548554,\n",
       " 0.00878804753932856,\n",
       " 0.00878804753932856,\n",
       " 0.007955041926385234,\n",
       " 0.007955041926385234,\n",
       " 0.007736705568288211,\n",
       " 0.007736705568288211,\n",
       " 0.007706292943113303,\n",
       " 0.007706292943113303,\n",
       " 0.007693021458849198,\n",
       " 0.007693021458849198,\n",
       " 0.007092605204657336,\n",
       " 0.007092605204657336,\n",
       " 0.00636615639492341,\n",
       " 0.00636615639492341,\n",
       " 0.005321328804792234,\n",
       " 0.005321328804792234,\n",
       " 0.004474581458361351,\n",
       " 0.004474581458361351,\n",
       " 0.0018502065720787462,\n",
       " 0.0018502065720787462,\n",
       " 0.0016004951019124008,\n",
       " 0.0016004951019124008,\n",
       " 0.0012758274999734836,\n",
       " 0.0012758274999734836,\n",
       " 0.0006851501965012601,\n",
       " 0.0006851501965012601,\n",
       " 0.0006121749966850116,\n",
       " 0.0006121749966850116,\n",
       " 0.00038333776763206764,\n",
       " 0.00038333776763206764,\n",
       " 3.347032897190087e-05,\n",
       " 3.347032897190087e-05]"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "abs_corrs_gbfs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.figure()\n",
    "lw = 2\n",
    "plt.plot(abs_corrs_gbdt, color='g',\n",
    "         lw=lw, label='GBDTBTt',marker=\"o\")\n",
    "plt.plot(abs_corrs_gbfs, color='darkorange',\n",
    "         lw=lw, label='GBFS',marker=\"o\")\n",
    "plt.ylim([0.6,1])\n",
    "plt.xlim([0,21])\n",
    "plt.xlabel('id')\n",
    "plt.ylabel('absolute correlations')\n",
    "plt.title('sorted absolute correlations')\n",
    "plt.legend(loc=\"lower right\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
